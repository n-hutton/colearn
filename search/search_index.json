{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to the Fetch.ai Collective Learning Library \u00b6 Colearn is a library that enables privacy-preserving decentralized machine learning tasks on the FET network. This blockchain-mediated collective learning system enables multiple stakeholders to build a shared machine learning model without needing to rely on a central authority. This library is currently in development. How collective learning works \u00b6 A group of learners come together, each of whom have their own datasets and want to collaborate on training a machine learning model. In each round of collective learning: One learner is selected to train the model and propose a new set of model weights. The other learners vote on whether the weights are an improvement. If the majority vote that the new weights are better than the old ones then the new weights are accepted by all the learners. Otherwise the new weights are discarded. The next round begins. For more information on the Collective Learning Protocol see here . Current Version \u00b6 We have released v.0.1 of Colearn Machine Learning Interface, the first version of an interface that will allow developers to prepare for future releases. Together with the interface we provide a simple backend for local experiments. This is the first backend with upcoming blockchain ledger based backends to follow. Future releases will use similar interfaces so that learners built with the current system will work on a different backend that integrates a distributed ledger and provides other improvements. The current framework will then be used mainly for model development and debugging. We invite all users to experiment with the framework, develop their own models, and provide feedback! Getting Started \u00b6 Download the source code from github: git clone https://github.com/fetchai/colearn.git && cd colearn Create and launch a clean virtual environment with Python 3.7. (This library has currently only been tested with Python 3.7). pipenv --python 3 .7 && pipenv shell Install the package from source: pip install -e . [ all ] For more installation options see Installation Run one of the examples: examples/pytorch_mnist.py For other examples see Examples . Writing your own models \u00b6 We encourage users to try out the system by writing their own models. Models need to implement the collective learning interface, which provides functions for training and voting on updates. More instructions can be found in the Getting Started section. Running the tests \u00b6 Tests can be run with: tox","title":"Colearn"},{"location":"#welcome-to-the-fetchai-collective-learning-library","text":"Colearn is a library that enables privacy-preserving decentralized machine learning tasks on the FET network. This blockchain-mediated collective learning system enables multiple stakeholders to build a shared machine learning model without needing to rely on a central authority. This library is currently in development.","title":"Welcome to the Fetch.ai Collective Learning Library"},{"location":"#how-collective-learning-works","text":"A group of learners come together, each of whom have their own datasets and want to collaborate on training a machine learning model. In each round of collective learning: One learner is selected to train the model and propose a new set of model weights. The other learners vote on whether the weights are an improvement. If the majority vote that the new weights are better than the old ones then the new weights are accepted by all the learners. Otherwise the new weights are discarded. The next round begins. For more information on the Collective Learning Protocol see here .","title":"How collective learning works"},{"location":"#current-version","text":"We have released v.0.1 of Colearn Machine Learning Interface, the first version of an interface that will allow developers to prepare for future releases. Together with the interface we provide a simple backend for local experiments. This is the first backend with upcoming blockchain ledger based backends to follow. Future releases will use similar interfaces so that learners built with the current system will work on a different backend that integrates a distributed ledger and provides other improvements. The current framework will then be used mainly for model development and debugging. We invite all users to experiment with the framework, develop their own models, and provide feedback!","title":"Current Version"},{"location":"#getting-started","text":"Download the source code from github: git clone https://github.com/fetchai/colearn.git && cd colearn Create and launch a clean virtual environment with Python 3.7. (This library has currently only been tested with Python 3.7). pipenv --python 3 .7 && pipenv shell Install the package from source: pip install -e . [ all ] For more installation options see Installation Run one of the examples: examples/pytorch_mnist.py For other examples see Examples .","title":"Getting Started"},{"location":"#writing-your-own-models","text":"We encourage users to try out the system by writing their own models. Models need to implement the collective learning interface, which provides functions for training and voting on updates. More instructions can be found in the Getting Started section.","title":"Writing your own models"},{"location":"#running-the-tests","text":"Tests can be run with: tox","title":"Running the tests"},{"location":"about/","text":"How collective learning works \u00b6 A Colearn experiment begins when a group of entities, a group of learners , decide on a model architecture and begin learning. Together they will train a single global model. The goal is to train a model that performs better than any of the learners can produce by training on their private data set. How Training Works \u00b6 Training occurs in rounds; during each round the learners attempt to improve the performance of the global shared model. To do so each round an update of the global model (for example new set of weights in a neural network) is proposed. The learners then validate the update and decide if the new model is better than the current global model. If enough learners approve the update then global model is updated. After an update is approved or rejected a new round begins. The detailed steps of a round updating a global model M are as follows: One of the learners is selected and proposes a new updated model M' The rest of the learners validate M' If M' has better performance than M then the learner votes to approve If not the learner votes to reject The total votes are tallied If more than some threshold (typically 50%) of learners approve then M' becomes the new global model. If not, M continues to be global model A new round begins. By using a decentralized ledger (a blockchain) this learning process can be run in a completely decentralized, secure and auditable way. Further security can be provided by using differential privacy when generating an update. The driver \u00b6 The driver implements the voting protocol, so it handles selecting a learner to train, sending the update out for voting, calculating the vote and accepting or declining the update. Here we have a very minimal driver that doesn't use networking or a blockchain. Eventually the driver will be a smart contract. This is the code that implements one round of voting: def run_one_round ( round_index : int , learners : Sequence [ MachineLearningInterface ], vote_threshold = 0.5 ): proposer = round_index % len ( learners ) new_weights = learners [ proposer ] . mli_propose_weights () prop_weights_list = [ ln . mli_test_weights ( new_weights ) for ln in learners ] approves = sum ( 1 if v . vote else 0 for v in prop_weights_list ) vote = False if approves >= len ( learners ) * vote_threshold : vote = True for j , learner in enumerate ( learners ): learner . mli_accept_weights ( prop_weights_list [ j ]) return prop_weights_list , vote The driver has a list of learners, and each round it selects one learner to be the proposer. The proposer does some training and proposes an updated set of weights. The driver then sends the proposed weights to each of the learners and they each vote on whether this is an improvement. If the number of approving votes is greater than the vote threshold the proposed weights are accepted, ad if not they're rejected. The MachineLearningInterface \u00b6 import abc from typing import Optional , Any , Dict from pydantic import BaseModel class Weights ( BaseModel ): weights : Any class ProposedWeights ( BaseModel ): weights : Weights vote_score : float test_score : float vote : bool evaluation_results : Optional [ Dict ] = None class MachineLearningInterface ( abc . ABC ): @abc . abstractmethod def mli_propose_weights ( self ) -> Weights : \"\"\" Trains the model. Returns new weights. Does not change the current weights of the model. \"\"\" pass @abc . abstractmethod def mli_test_weights ( self , weights : Weights ) -> ProposedWeights : \"\"\" Tests the proposed weights and fills in the rest of the fields \"\"\" @abc . abstractmethod def mli_accept_weights ( self , weights : Weights ): \"\"\" Updates the model with the proposed set of weights :param weights: The new weights \"\"\" pass @abc . abstractmethod def mli_get_current_weights ( self ) -> Weights : \"\"\" Returns the current weights of the model \"\"\" pass There are four methods that need to be implemented: propose_weights causes the model to do some training and then return a new set of weights that are propsed to the other learners. This method shouldn't change the current weights of the model - that only happens when accept_weights is called. test_weights - the models takes some new weights and returns a vote on whether the new weights are an improvement. As in propse_weights, this shouldn't change the current weights of the model - that only happens when accept_weights is called. accept_weights - the models accepts some weights that have been voted on and approved by the set of learners. The old weighs of the model are discarded and replaced by the new weights. current_weights should return the current weights of the model. For more details about directly implementing the machine learning interface see the tutorial here","title":"Collective Learning Protocol"},{"location":"about/#how-collective-learning-works","text":"A Colearn experiment begins when a group of entities, a group of learners , decide on a model architecture and begin learning. Together they will train a single global model. The goal is to train a model that performs better than any of the learners can produce by training on their private data set.","title":"How collective learning works"},{"location":"about/#how-training-works","text":"Training occurs in rounds; during each round the learners attempt to improve the performance of the global shared model. To do so each round an update of the global model (for example new set of weights in a neural network) is proposed. The learners then validate the update and decide if the new model is better than the current global model. If enough learners approve the update then global model is updated. After an update is approved or rejected a new round begins. The detailed steps of a round updating a global model M are as follows: One of the learners is selected and proposes a new updated model M' The rest of the learners validate M' If M' has better performance than M then the learner votes to approve If not the learner votes to reject The total votes are tallied If more than some threshold (typically 50%) of learners approve then M' becomes the new global model. If not, M continues to be global model A new round begins. By using a decentralized ledger (a blockchain) this learning process can be run in a completely decentralized, secure and auditable way. Further security can be provided by using differential privacy when generating an update.","title":"How Training Works"},{"location":"about/#the-driver","text":"The driver implements the voting protocol, so it handles selecting a learner to train, sending the update out for voting, calculating the vote and accepting or declining the update. Here we have a very minimal driver that doesn't use networking or a blockchain. Eventually the driver will be a smart contract. This is the code that implements one round of voting: def run_one_round ( round_index : int , learners : Sequence [ MachineLearningInterface ], vote_threshold = 0.5 ): proposer = round_index % len ( learners ) new_weights = learners [ proposer ] . mli_propose_weights () prop_weights_list = [ ln . mli_test_weights ( new_weights ) for ln in learners ] approves = sum ( 1 if v . vote else 0 for v in prop_weights_list ) vote = False if approves >= len ( learners ) * vote_threshold : vote = True for j , learner in enumerate ( learners ): learner . mli_accept_weights ( prop_weights_list [ j ]) return prop_weights_list , vote The driver has a list of learners, and each round it selects one learner to be the proposer. The proposer does some training and proposes an updated set of weights. The driver then sends the proposed weights to each of the learners and they each vote on whether this is an improvement. If the number of approving votes is greater than the vote threshold the proposed weights are accepted, ad if not they're rejected.","title":"The driver"},{"location":"about/#the-machinelearninginterface","text":"import abc from typing import Optional , Any , Dict from pydantic import BaseModel class Weights ( BaseModel ): weights : Any class ProposedWeights ( BaseModel ): weights : Weights vote_score : float test_score : float vote : bool evaluation_results : Optional [ Dict ] = None class MachineLearningInterface ( abc . ABC ): @abc . abstractmethod def mli_propose_weights ( self ) -> Weights : \"\"\" Trains the model. Returns new weights. Does not change the current weights of the model. \"\"\" pass @abc . abstractmethod def mli_test_weights ( self , weights : Weights ) -> ProposedWeights : \"\"\" Tests the proposed weights and fills in the rest of the fields \"\"\" @abc . abstractmethod def mli_accept_weights ( self , weights : Weights ): \"\"\" Updates the model with the proposed set of weights :param weights: The new weights \"\"\" pass @abc . abstractmethod def mli_get_current_weights ( self ) -> Weights : \"\"\" Returns the current weights of the model \"\"\" pass There are four methods that need to be implemented: propose_weights causes the model to do some training and then return a new set of weights that are propsed to the other learners. This method shouldn't change the current weights of the model - that only happens when accept_weights is called. test_weights - the models takes some new weights and returns a vote on whether the new weights are an improvement. As in propse_weights, this shouldn't change the current weights of the model - that only happens when accept_weights is called. accept_weights - the models accepts some weights that have been voted on and approved by the set of learners. The old weighs of the model are discarded and replaced by the new weights. current_weights should return the current weights of the model. For more details about directly implementing the machine learning interface see the tutorial here","title":"The MachineLearningInterface"},{"location":"demo/","text":"How to run the demo \u00b6 You can try collective learning for yourself using the simple demo in ./bin/run_demo.py . This demo creates n learners for one of five learning tasks and co-ordinates the collective learning between them. There are five potential datasets for the demo KERAS_MNIST is the Tensorflow implementation of standard handwritten digits recognition dataset KERAS_CIFAR10 is the Tensorflow implementation of standard image recognition dataset PYTORCH_XRAY is Pytorch implementation of a binary classification task that requires predicting pneumonia from images of chest X-rays. The data need to be downloaded from kaggle PYTORCH_COVID_XRAY is Pytorch implementation of a 3 class classification task that requires predicting no finding, covid or pneumonia from images of chest X-rays. This dataset is currently unavailable. FRAUD The fraud dataset consists of information about credit card transactions, and the task is to predict whether transactions are fraudulent or not. The data need to be downloaded from kaggle Use the -h flag to see the options: examples/run_demo.py -h Arguments to run the demo: --data_dir: Directory containing training data, not required for MNIST and CIFAR10 --test_dir: Optional directory containing test data. A fraction of the training set will be used as a test set when not specified --task: Type of task for machine learning: KERAS_MNIST, KERAS_CIFAR10, FRAUD, PYTORCH_XRAY, PYTORCH_COVID_XRAY --model_type: Type of machine learning model, default model will be used if not specified --n_learners: Number of individual learners --n_epochs: Number of training epochs --vote_threshold: Minimum fraction of positive votes to accept the new model --train_ratio: Fraction of training dataset to be used as test-set when no test-set is specified --seed: Seed for initialising model and shuffling datasets --learning_rate: Learning rate for optimiser --batch_size: Size of training batch Running MNIST \u00b6 The simplest task to run is MNIST because this doesn't require downloading the data. This runs the MNIST task with five learners for 15 rounds. examples/run_demo.py --task KERAS_MNIST --n_learners 5 --n_epochs 15 You should see a graph of the vote score and the test score (the score used here is categorical accuracy). New model is accepted (blue star) if amount of possitive votes (yellow color) is higher than 0.5. New model is rejected (orange cross) if amount of negative votes (purple color) is lower than 0.5. As you can see, there are five learners, and initially they perform poorly. In round one, learner 0 is selected to propose a new set of weights. Other datasets \u00b6 To run the CIFAR10 dataset: examples/run_demo.py --task KERAS_CIFAR10 --n_learners 5 --n_epochs 15 The Fraud and X-ray datasets need to be downloaded from kaggle (this requires a kaggle account). To run the fraud dataset: examples/run_demo.py --task FRAUD --n_learners 5 --n_epochs 15 --data_dir ./data/fraud To run the X-ray dataset: examples/run_demo.py --task PYTORCH_XRAY --n_learners 5 -n_epochs 15 -data_dir ./data/xray","title":"Demo"},{"location":"demo/#how-to-run-the-demo","text":"You can try collective learning for yourself using the simple demo in ./bin/run_demo.py . This demo creates n learners for one of five learning tasks and co-ordinates the collective learning between them. There are five potential datasets for the demo KERAS_MNIST is the Tensorflow implementation of standard handwritten digits recognition dataset KERAS_CIFAR10 is the Tensorflow implementation of standard image recognition dataset PYTORCH_XRAY is Pytorch implementation of a binary classification task that requires predicting pneumonia from images of chest X-rays. The data need to be downloaded from kaggle PYTORCH_COVID_XRAY is Pytorch implementation of a 3 class classification task that requires predicting no finding, covid or pneumonia from images of chest X-rays. This dataset is currently unavailable. FRAUD The fraud dataset consists of information about credit card transactions, and the task is to predict whether transactions are fraudulent or not. The data need to be downloaded from kaggle Use the -h flag to see the options: examples/run_demo.py -h Arguments to run the demo: --data_dir: Directory containing training data, not required for MNIST and CIFAR10 --test_dir: Optional directory containing test data. A fraction of the training set will be used as a test set when not specified --task: Type of task for machine learning: KERAS_MNIST, KERAS_CIFAR10, FRAUD, PYTORCH_XRAY, PYTORCH_COVID_XRAY --model_type: Type of machine learning model, default model will be used if not specified --n_learners: Number of individual learners --n_epochs: Number of training epochs --vote_threshold: Minimum fraction of positive votes to accept the new model --train_ratio: Fraction of training dataset to be used as test-set when no test-set is specified --seed: Seed for initialising model and shuffling datasets --learning_rate: Learning rate for optimiser --batch_size: Size of training batch","title":"How to run the demo"},{"location":"demo/#running-mnist","text":"The simplest task to run is MNIST because this doesn't require downloading the data. This runs the MNIST task with five learners for 15 rounds. examples/run_demo.py --task KERAS_MNIST --n_learners 5 --n_epochs 15 You should see a graph of the vote score and the test score (the score used here is categorical accuracy). New model is accepted (blue star) if amount of possitive votes (yellow color) is higher than 0.5. New model is rejected (orange cross) if amount of negative votes (purple color) is lower than 0.5. As you can see, there are five learners, and initially they perform poorly. In round one, learner 0 is selected to propose a new set of weights.","title":"Running MNIST"},{"location":"demo/#other-datasets","text":"To run the CIFAR10 dataset: examples/run_demo.py --task KERAS_CIFAR10 --n_learners 5 --n_epochs 15 The Fraud and X-ray datasets need to be downloaded from kaggle (this requires a kaggle account). To run the fraud dataset: examples/run_demo.py --task FRAUD --n_learners 5 --n_epochs 15 --data_dir ./data/fraud To run the X-ray dataset: examples/run_demo.py --task PYTORCH_XRAY --n_learners 5 -n_epochs 15 -data_dir ./data/xray","title":"Other datasets"},{"location":"differential_privacy/","text":"What is differential privacy? \u00b6 Differential privacy (DP) is a system for publicly sharing information about a dataset by describing the patterns of groups within the dataset while withholding information about individuals in the dataset. The idea behind differential privacy is that if the effect of making an arbitrary single substitution in the database is small enough, the query result cannot be used to infer much about any single individual, and therefore provides privacy. How to use differential privacy with colearn \u00b6 The opacus and tensorflow-privacy libraries implement DP for pytorch and keras respectively. To see an example of using them see dp_pytorch and dp_keras .","title":"Differential Privacy"},{"location":"differential_privacy/#what-is-differential-privacy","text":"Differential privacy (DP) is a system for publicly sharing information about a dataset by describing the patterns of groups within the dataset while withholding information about individuals in the dataset. The idea behind differential privacy is that if the effect of making an arbitrary single substitution in the database is small enough, the query result cannot be used to infer much about any single individual, and therefore provides privacy.","title":"What is differential privacy?"},{"location":"differential_privacy/#how-to-use-differential-privacy-with-colearn","text":"The opacus and tensorflow-privacy libraries implement DP for pytorch and keras respectively. To see an example of using them see dp_pytorch and dp_keras .","title":"How to use differential privacy with colearn"},{"location":"examples/","text":"Examples that use Collective Learning \u00b6 This is a list of examples that we've implemented to show you how to use Collective Learning Mnist \u00b6 Uses the standard Mnist database of handwritten images mnist_keras . Uses the KerasLearner helper class. Discussed in more detail here . mnist_pytorch . Uses the PytorchLearner helper class. Discussed in more detail here . Fraud \u00b6 The fraud dataset consists of information about credit card transactions. The task is to predict whether transactions are fraudulent or not. The data needs to be downloaded from Kaggle fraud_mli . Uses the MachineLearningInterface directly and detects fraud in bank transactions. fraud_keras . Loads data from numpy arrays and uses KerasLearner . Cifar10 \u00b6 Uses the standard Cifar10 database of images cifar_keras . Uses the KerasLearner helper class. cifar_pytorch . Uses the PytorchLearner helper class. Xray \u00b6 A binary classification task that requires predicting pneumonia from images of chest X-rays. The data need to be downloaded from Kaggle xray_keras . Uses the KerasLearner helper class. xray_pytorch . Uses the PytorchLearner helper class.","title":"Standalone examples"},{"location":"examples/#examples-that-use-collective-learning","text":"This is a list of examples that we've implemented to show you how to use Collective Learning","title":"Examples that use Collective Learning"},{"location":"examples/#mnist","text":"Uses the standard Mnist database of handwritten images mnist_keras . Uses the KerasLearner helper class. Discussed in more detail here . mnist_pytorch . Uses the PytorchLearner helper class. Discussed in more detail here .","title":"Mnist"},{"location":"examples/#fraud","text":"The fraud dataset consists of information about credit card transactions. The task is to predict whether transactions are fraudulent or not. The data needs to be downloaded from Kaggle fraud_mli . Uses the MachineLearningInterface directly and detects fraud in bank transactions. fraud_keras . Loads data from numpy arrays and uses KerasLearner .","title":"Fraud"},{"location":"examples/#cifar10","text":"Uses the standard Cifar10 database of images cifar_keras . Uses the KerasLearner helper class. cifar_pytorch . Uses the PytorchLearner helper class.","title":"Cifar10"},{"location":"examples/#xray","text":"A binary classification task that requires predicting pneumonia from images of chest X-rays. The data need to be downloaded from Kaggle xray_keras . Uses the KerasLearner helper class. xray_pytorch . Uses the PytorchLearner helper class.","title":"Xray"},{"location":"installation/","text":"Installation \u00b6 The core package, colearn , contains only the MachineLearningInterface and a simple driver that implements the Collective Learning Protocol. To install only the core package: pip install . To make collective learning easier to use we have defined extra packages with helpers for model development in Keras and Pytorch. To install with Keras/Pytorch extras: pip install .[keras] pip install .[pytorch] To install all the extras, including the ones required for the examples, use: pip install .[all] If you are developing the colearn library then install it in editable mode so that new changes are effective immediately: pip install -e .[all]","title":"Installation"},{"location":"installation/#installation","text":"The core package, colearn , contains only the MachineLearningInterface and a simple driver that implements the Collective Learning Protocol. To install only the core package: pip install . To make collective learning easier to use we have defined extra packages with helpers for model development in Keras and Pytorch. To install with Keras/Pytorch extras: pip install .[keras] pip install .[pytorch] To install all the extras, including the ones required for the examples, use: pip install .[all] If you are developing the colearn library then install it in editable mode so that new changes are effective immediately: pip install -e .[all]","title":"Installation"},{"location":"intro_tutorial_keras/","text":"Using collective learning with keras \u00b6 This tutorial is a simple guide to trying out the collective learning protocol with your own machine learning code. Everything runs locally. The most flexible way to use the collective learning backends is to make a class that implements the Collective Learning MachineLearningInterface defined in ml_interface.py . For more details on how to use the MachineLearningInterface see here However, the simpler way is to use one of the helper classes that we have provided that implement most of the interface for popular ML libraries. In this tutorial we are going to walk through using the KerasLearner . First we are going to define the model architecture, then we are going to load the data and configure the model, and then we will run Collective Learning. A standard script for machine learning with Keras looks like the one below import tensorflow as tf import tensorflow_datasets as tfds n_rounds = 20 width = 28 height = 28 n_classes = 10 l_rate = 0.001 batch_size = 64 # Load the data train_dataset = tfds . load ( 'mnist' , split = 'train' , as_supervised = True ) test_dataset = tfds . load ( 'mnist' , split = 'test' , as_supervised = True ) def normalize_img ( image , label ): \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\" return tf . cast ( image , tf . float32 ) / 255. , label train_dataset = train_dataset . map ( normalize_img , num_parallel_calls = tf . data . experimental . AUTOTUNE ) train_dataset = train_dataset . shuffle ( len ( train_dataset )) train_dataset = train_dataset . batch ( batch_size ) test_dataset = test_dataset . map ( normalize_img , num_parallel_calls = tf . data . experimental . AUTOTUNE ) test_dataset = test_dataset . shuffle ( len ( test_dataset )) test_dataset = test_dataset . batch ( batch_size ) # Define the model input_img = tf . keras . Input ( shape = ( width , height , 1 ), name = \"Input\" ) x = tf . keras . layers . Conv2D ( 64 , ( 3 , 3 ), activation = \"relu\" , padding = \"same\" , name = \"Conv1_1\" )( input_img ) x = tf . keras . layers . BatchNormalization ( name = \"bn1\" )( x ) x = tf . keras . layers . MaxPooling2D (( 2 , 2 ), name = \"pool1\" )( x ) x = tf . keras . layers . Conv2D ( 128 , ( 3 , 3 ), activation = \"relu\" , padding = \"same\" , name = \"Conv2_1\" )( x ) x = tf . keras . layers . BatchNormalization ( name = \"bn4\" )( x ) x = tf . keras . layers . MaxPooling2D (( 2 , 2 ), name = \"pool2\" )( x ) x = tf . keras . layers . Flatten ( name = \"flatten\" )( x ) x = tf . keras . layers . Dense ( n_classes , activation = \"softmax\" , name = \"fc1\" )( x ) model = tf . keras . Model ( inputs = input_img , outputs = x ) opt = tf . keras . optimizers . Adam ( lr = l_rate ) model . compile ( loss = \"sparse_categorical_crossentropy\" , metrics = [ tf . keras . metrics . SparseCategoricalAccuracy ()], optimizer = opt ) # Train and evaluate model for round in range ( n_rounds ): model . fit ( train_dataset , steps_per_epoch = 40 ) result = model . evaluate ( x = test_dataset , return_dict = True , steps = 10 ) print ( f \"Performance at round { round } is { result } \" ) There are three steps: Load the data Define the model Train the model In this tutorial we are going to see how to modify each step to use collective learning. We'll end up with code like this: import tensorflow as tf import tensorflow_datasets as tfds from colearn.training import initial_result , collective_learning_round , set_equal_weights from colearn.utils.plot import ColearnPlot from colearn.utils.results import Results from colearn_keras.keras_learner import KerasLearner \"\"\" MNIST training example using Keras Used dataset: - MNIST is set of 60 000 black and white hand written digits images of size 28x28x1 in 10 classes What script does: - Loads MNIST dataset from Keras - Sets up a Keras learner - Randomly splits dataset between multiple learners - Does multiple rounds of learning process and displays plot with results \"\"\" n_learners = 5 vote_threshold = 0.5 vote_batches = 2 n_epochs = 20 width = 28 height = 28 n_classes = 10 l_rate = 0.001 batch_size = 64 # Load data for each learner train_dataset = tfds . load ( 'mnist' , split = 'train' , as_supervised = True ) train_datasets = [ train_dataset . shard ( num_shards = n_learners , index = i ) for i in range ( n_learners )] test_dataset = tfds . load ( 'mnist' , split = 'test' , as_supervised = True ) test_datasets = [ test_dataset . shard ( num_shards = n_learners , index = i ) for i in range ( n_learners )] def normalize_img ( image , label ): \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\" return tf . cast ( image , tf . float32 ) / 255. , label for i in range ( n_learners ): train_datasets [ i ] = train_datasets [ i ] . map ( normalize_img , num_parallel_calls = tf . data . experimental . AUTOTUNE ) train_datasets [ i ] = train_datasets [ i ] . shuffle ( len ( train_datasets [ i ])) train_datasets [ i ] = train_datasets [ i ] . batch ( batch_size ) test_datasets [ i ] = test_datasets [ i ] . map ( normalize_img , num_parallel_calls = tf . data . experimental . AUTOTUNE ) test_datasets [ i ] = test_datasets [ i ] . shuffle ( len ( test_datasets [ i ])) test_datasets [ i ] = test_datasets [ i ] . batch ( batch_size ) # Define model def get_model (): input_img = tf . keras . Input ( shape = ( width , height , 1 ), name = \"Input\" ) x = tf . keras . layers . Conv2D ( 64 , ( 3 , 3 ), activation = \"relu\" , padding = \"same\" , name = \"Conv1_1\" )( input_img ) x = tf . keras . layers . BatchNormalization ( name = \"bn1\" )( x ) x = tf . keras . layers . MaxPooling2D (( 2 , 2 ), name = \"pool1\" )( x ) x = tf . keras . layers . Conv2D ( 128 , ( 3 , 3 ), activation = \"relu\" , padding = \"same\" , name = \"Conv2_1\" )( x ) x = tf . keras . layers . BatchNormalization ( name = \"bn4\" )( x ) x = tf . keras . layers . MaxPooling2D (( 2 , 2 ), name = \"pool2\" )( x ) x = tf . keras . layers . Flatten ( name = \"flatten\" )( x ) x = tf . keras . layers . Dense ( n_classes , activation = \"softmax\" , name = \"fc1\" )( x ) model = tf . keras . Model ( inputs = input_img , outputs = x ) opt = tf . keras . optimizers . Adam ( lr = l_rate ) model . compile ( loss = \"sparse_categorical_crossentropy\" , metrics = [ tf . keras . metrics . SparseCategoricalAccuracy ()], optimizer = opt ) return model all_learner_models = [] for i in range ( n_learners ): all_learner_models . append ( KerasLearner ( model = get_model (), train_loader = train_datasets [ i ], test_loader = test_datasets [ i ], criterion = \"sparse_categorical_accuracy\" , minimise_criterion = False , model_evaluate_kwargs = { \"steps\" : vote_batches }, )) set_equal_weights ( all_learner_models ) # Train the model using Collective Learning results = Results () results . data . append ( initial_result ( all_learner_models )) plot = ColearnPlot ( n_learners = n_learners , score_name = all_learner_models [ 0 ] . criterion ) for epoch in range ( n_epochs ): results . data . append ( collective_learning_round ( all_learner_models , vote_threshold , epoch ) ) plot . plot_results ( results ) plot . plot_votes ( results ) plot . plot_results ( results ) plot . plot_votes ( results , block = True ) print ( \"Colearn Example Finished!\" ) The first thing is to modify the data loading code. Each learner needs to have their own training and testing set from the data. This is easy to do with keras: train_datasets = [ train_dataset . shard ( num_shards = n_learners , index = i ) for i in range ( n_learners )] The model definition is very similar too, except that each learner will need its own copy of the model, so we've moved it into a function. To use collective learning, we need to create an object that implements the MachineLearningInterface. To make it easier to use the MachineLearningInterface with keras, we've defined KerasLearner . KerasLearner implements standard training and evaluation routines as well as the MachineLearningInterface methods. from inspect import signature from typing import Optional try : import tensorflow as tf except ImportError : raise Exception ( \"Tensorflow is not installed. To use the tensorflow/keras \" \"add-ons please install colearn with `pip install colearn[keras]`.\" ) from tensorflow import keras from colearn.ml_interface import MachineLearningInterface , Weights , ProposedWeights class KerasLearner ( MachineLearningInterface ): \"\"\" Tensorflow Keras learner implementation of machine learning interface \"\"\" def __init__ ( self , model : keras . Model , train_loader : tf . data . Dataset , test_loader : Optional [ tf . data . Dataset ] = None , minimise_criterion : bool = True , criterion : str = 'loss' , model_fit_kwargs : Optional [ dict ] = None , model_evaluate_kwargs : Optional [ dict ] = None ): \"\"\" :param model: Keras model used for training :param train_loader: Training dataset :param test_loader: Optional test set. Subset of training set will be used if not specified. :param minimise_criterion: Boolean - True to minimise value of criterion, False to maximise :param criterion: Function to measure model performance :param model_fit_kwargs: Arguments to be passed on model.fit function call :param model_evaluate_kwargs: Arguments to be passed on model.evaluate function call \"\"\" self . model : keras . Model = model self . train_loader : tf . data . Dataset = train_loader self . test_loader : Optional [ tf . data . Dataset ] = test_loader self . minimise_criterion : bool = minimise_criterion self . criterion = criterion self . model_fit_kwargs = model_fit_kwargs or {} if model_fit_kwargs : # check that these are valid kwargs for model fit sig = signature ( self . model . fit ) try : sig . bind_partial ( ** self . model_fit_kwargs ) except TypeError : raise Exception ( \"Invalid arguments for model.fit\" ) self . model_evaluate_kwargs = model_evaluate_kwargs or {} if model_evaluate_kwargs : # check that these are valid kwargs for model evaluate sig = signature ( self . model . evaluate ) try : sig . bind_partial ( ** self . model_evaluate_kwargs ) except TypeError : raise Exception ( \"Invalid arguments for model.evaluate\" ) self . vote_score : float = self . test ( self . train_loader ) def mli_propose_weights ( self ) -> Weights : \"\"\" Trains model on training set and returns new weights after training - Current model is reverted to original state after training :return: Weights after training \"\"\" current_weights = self . mli_get_current_weights () self . train () new_weights = self . mli_get_current_weights () self . set_weights ( current_weights ) return new_weights def mli_test_weights ( self , weights : Weights ) -> ProposedWeights : \"\"\" Tests given weights on training and test set and returns weights with score values :param weights: Weights to be tested :return: ProposedWeights - Weights with vote and test score \"\"\" current_weights = self . mli_get_current_weights () self . set_weights ( weights ) vote_score = self . test ( self . train_loader ) if self . test_loader : test_score = self . test ( self . test_loader ) else : test_score = 0 vote = self . vote ( vote_score ) self . set_weights ( current_weights ) return ProposedWeights ( weights = weights , vote_score = vote_score , test_score = test_score , vote = vote ) def vote ( self , new_score ) -> bool : \"\"\" Compares current model score with proposed model score and returns vote :param new_score: Proposed score :return: bool positive or negative vote \"\"\" if self . minimise_criterion : return new_score <= self . vote_score else : return new_score >= self . vote_score def mli_accept_weights ( self , weights : Weights ): \"\"\" Updates the model with the proposed set of weights :param weights: The new weights \"\"\" self . set_weights ( weights ) self . vote_score = self . test ( self . train_loader ) def mli_get_current_weights ( self ) -> Weights : \"\"\" :return: The current weights of the model \"\"\" return Weights ( weights = self . model . get_weights ()) def set_weights ( self , weights : Weights ): \"\"\" Rewrites weight of current model :param weights: Weights to be stored \"\"\" self . model . set_weights ( weights . weights ) def train ( self ): \"\"\" Trains the model on the training dataset \"\"\" self . model . fit ( self . train_loader , ** self . model_fit_kwargs ) def test ( self , loader : tf . data . Dataset ) -> float : \"\"\" Tests performance of the model on specified dataset :param loader: Dataset for testing :return: Value of performance metric \"\"\" result = self . model . evaluate ( x = loader , return_dict = True , ** self . model_evaluate_kwargs ) return result [ self . criterion ] We create a set of KerasLearners by passing in the model and the datasets: all_learner_models = [] for i in range ( n_learners ): all_learner_models . append ( KerasLearner ( model = get_model (), train_loader = train_datasets [ i ], test_loader = test_datasets [ i ], criterion = \"sparse_categorical_accuracy\" , minimise_criterion = False , model_evaluate_kwargs = { \"steps\" : vote_batches }, )) Then we give all the models the same weights to start off with: set_equal_weights ( all_learner_models ) And then we can move on to the final stage, which is training with Collective Learning. The function collective_learning_round performs one round of collective learning. One learner is selected to train and propose an update. The other learners vote on the update, and if the vote passes then the update is accepted. Then a new round begins. # Train the model using Collective Learning results = Results () results . data . append ( initial_result ( all_learner_models )) for round in range ( n_rounds ): results . data . append ( collective_learning_round ( all_learner_models , vote_threshold , round ) ) plot_results ( results , n_learners , block = False , score_name = all_learner_models [ 0 ] . criterion ) plot_votes ( results , block = False ) plot_results ( results , n_learners , block = False , score_name = all_learner_models [ 0 ] . criterion ) plot_votes ( results , block = True ) Simple!","title":"Keras"},{"location":"intro_tutorial_keras/#using-collective-learning-with-keras","text":"This tutorial is a simple guide to trying out the collective learning protocol with your own machine learning code. Everything runs locally. The most flexible way to use the collective learning backends is to make a class that implements the Collective Learning MachineLearningInterface defined in ml_interface.py . For more details on how to use the MachineLearningInterface see here However, the simpler way is to use one of the helper classes that we have provided that implement most of the interface for popular ML libraries. In this tutorial we are going to walk through using the KerasLearner . First we are going to define the model architecture, then we are going to load the data and configure the model, and then we will run Collective Learning. A standard script for machine learning with Keras looks like the one below import tensorflow as tf import tensorflow_datasets as tfds n_rounds = 20 width = 28 height = 28 n_classes = 10 l_rate = 0.001 batch_size = 64 # Load the data train_dataset = tfds . load ( 'mnist' , split = 'train' , as_supervised = True ) test_dataset = tfds . load ( 'mnist' , split = 'test' , as_supervised = True ) def normalize_img ( image , label ): \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\" return tf . cast ( image , tf . float32 ) / 255. , label train_dataset = train_dataset . map ( normalize_img , num_parallel_calls = tf . data . experimental . AUTOTUNE ) train_dataset = train_dataset . shuffle ( len ( train_dataset )) train_dataset = train_dataset . batch ( batch_size ) test_dataset = test_dataset . map ( normalize_img , num_parallel_calls = tf . data . experimental . AUTOTUNE ) test_dataset = test_dataset . shuffle ( len ( test_dataset )) test_dataset = test_dataset . batch ( batch_size ) # Define the model input_img = tf . keras . Input ( shape = ( width , height , 1 ), name = \"Input\" ) x = tf . keras . layers . Conv2D ( 64 , ( 3 , 3 ), activation = \"relu\" , padding = \"same\" , name = \"Conv1_1\" )( input_img ) x = tf . keras . layers . BatchNormalization ( name = \"bn1\" )( x ) x = tf . keras . layers . MaxPooling2D (( 2 , 2 ), name = \"pool1\" )( x ) x = tf . keras . layers . Conv2D ( 128 , ( 3 , 3 ), activation = \"relu\" , padding = \"same\" , name = \"Conv2_1\" )( x ) x = tf . keras . layers . BatchNormalization ( name = \"bn4\" )( x ) x = tf . keras . layers . MaxPooling2D (( 2 , 2 ), name = \"pool2\" )( x ) x = tf . keras . layers . Flatten ( name = \"flatten\" )( x ) x = tf . keras . layers . Dense ( n_classes , activation = \"softmax\" , name = \"fc1\" )( x ) model = tf . keras . Model ( inputs = input_img , outputs = x ) opt = tf . keras . optimizers . Adam ( lr = l_rate ) model . compile ( loss = \"sparse_categorical_crossentropy\" , metrics = [ tf . keras . metrics . SparseCategoricalAccuracy ()], optimizer = opt ) # Train and evaluate model for round in range ( n_rounds ): model . fit ( train_dataset , steps_per_epoch = 40 ) result = model . evaluate ( x = test_dataset , return_dict = True , steps = 10 ) print ( f \"Performance at round { round } is { result } \" ) There are three steps: Load the data Define the model Train the model In this tutorial we are going to see how to modify each step to use collective learning. We'll end up with code like this: import tensorflow as tf import tensorflow_datasets as tfds from colearn.training import initial_result , collective_learning_round , set_equal_weights from colearn.utils.plot import ColearnPlot from colearn.utils.results import Results from colearn_keras.keras_learner import KerasLearner \"\"\" MNIST training example using Keras Used dataset: - MNIST is set of 60 000 black and white hand written digits images of size 28x28x1 in 10 classes What script does: - Loads MNIST dataset from Keras - Sets up a Keras learner - Randomly splits dataset between multiple learners - Does multiple rounds of learning process and displays plot with results \"\"\" n_learners = 5 vote_threshold = 0.5 vote_batches = 2 n_epochs = 20 width = 28 height = 28 n_classes = 10 l_rate = 0.001 batch_size = 64 # Load data for each learner train_dataset = tfds . load ( 'mnist' , split = 'train' , as_supervised = True ) train_datasets = [ train_dataset . shard ( num_shards = n_learners , index = i ) for i in range ( n_learners )] test_dataset = tfds . load ( 'mnist' , split = 'test' , as_supervised = True ) test_datasets = [ test_dataset . shard ( num_shards = n_learners , index = i ) for i in range ( n_learners )] def normalize_img ( image , label ): \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\" return tf . cast ( image , tf . float32 ) / 255. , label for i in range ( n_learners ): train_datasets [ i ] = train_datasets [ i ] . map ( normalize_img , num_parallel_calls = tf . data . experimental . AUTOTUNE ) train_datasets [ i ] = train_datasets [ i ] . shuffle ( len ( train_datasets [ i ])) train_datasets [ i ] = train_datasets [ i ] . batch ( batch_size ) test_datasets [ i ] = test_datasets [ i ] . map ( normalize_img , num_parallel_calls = tf . data . experimental . AUTOTUNE ) test_datasets [ i ] = test_datasets [ i ] . shuffle ( len ( test_datasets [ i ])) test_datasets [ i ] = test_datasets [ i ] . batch ( batch_size ) # Define model def get_model (): input_img = tf . keras . Input ( shape = ( width , height , 1 ), name = \"Input\" ) x = tf . keras . layers . Conv2D ( 64 , ( 3 , 3 ), activation = \"relu\" , padding = \"same\" , name = \"Conv1_1\" )( input_img ) x = tf . keras . layers . BatchNormalization ( name = \"bn1\" )( x ) x = tf . keras . layers . MaxPooling2D (( 2 , 2 ), name = \"pool1\" )( x ) x = tf . keras . layers . Conv2D ( 128 , ( 3 , 3 ), activation = \"relu\" , padding = \"same\" , name = \"Conv2_1\" )( x ) x = tf . keras . layers . BatchNormalization ( name = \"bn4\" )( x ) x = tf . keras . layers . MaxPooling2D (( 2 , 2 ), name = \"pool2\" )( x ) x = tf . keras . layers . Flatten ( name = \"flatten\" )( x ) x = tf . keras . layers . Dense ( n_classes , activation = \"softmax\" , name = \"fc1\" )( x ) model = tf . keras . Model ( inputs = input_img , outputs = x ) opt = tf . keras . optimizers . Adam ( lr = l_rate ) model . compile ( loss = \"sparse_categorical_crossentropy\" , metrics = [ tf . keras . metrics . SparseCategoricalAccuracy ()], optimizer = opt ) return model all_learner_models = [] for i in range ( n_learners ): all_learner_models . append ( KerasLearner ( model = get_model (), train_loader = train_datasets [ i ], test_loader = test_datasets [ i ], criterion = \"sparse_categorical_accuracy\" , minimise_criterion = False , model_evaluate_kwargs = { \"steps\" : vote_batches }, )) set_equal_weights ( all_learner_models ) # Train the model using Collective Learning results = Results () results . data . append ( initial_result ( all_learner_models )) plot = ColearnPlot ( n_learners = n_learners , score_name = all_learner_models [ 0 ] . criterion ) for epoch in range ( n_epochs ): results . data . append ( collective_learning_round ( all_learner_models , vote_threshold , epoch ) ) plot . plot_results ( results ) plot . plot_votes ( results ) plot . plot_results ( results ) plot . plot_votes ( results , block = True ) print ( \"Colearn Example Finished!\" ) The first thing is to modify the data loading code. Each learner needs to have their own training and testing set from the data. This is easy to do with keras: train_datasets = [ train_dataset . shard ( num_shards = n_learners , index = i ) for i in range ( n_learners )] The model definition is very similar too, except that each learner will need its own copy of the model, so we've moved it into a function. To use collective learning, we need to create an object that implements the MachineLearningInterface. To make it easier to use the MachineLearningInterface with keras, we've defined KerasLearner . KerasLearner implements standard training and evaluation routines as well as the MachineLearningInterface methods. from inspect import signature from typing import Optional try : import tensorflow as tf except ImportError : raise Exception ( \"Tensorflow is not installed. To use the tensorflow/keras \" \"add-ons please install colearn with `pip install colearn[keras]`.\" ) from tensorflow import keras from colearn.ml_interface import MachineLearningInterface , Weights , ProposedWeights class KerasLearner ( MachineLearningInterface ): \"\"\" Tensorflow Keras learner implementation of machine learning interface \"\"\" def __init__ ( self , model : keras . Model , train_loader : tf . data . Dataset , test_loader : Optional [ tf . data . Dataset ] = None , minimise_criterion : bool = True , criterion : str = 'loss' , model_fit_kwargs : Optional [ dict ] = None , model_evaluate_kwargs : Optional [ dict ] = None ): \"\"\" :param model: Keras model used for training :param train_loader: Training dataset :param test_loader: Optional test set. Subset of training set will be used if not specified. :param minimise_criterion: Boolean - True to minimise value of criterion, False to maximise :param criterion: Function to measure model performance :param model_fit_kwargs: Arguments to be passed on model.fit function call :param model_evaluate_kwargs: Arguments to be passed on model.evaluate function call \"\"\" self . model : keras . Model = model self . train_loader : tf . data . Dataset = train_loader self . test_loader : Optional [ tf . data . Dataset ] = test_loader self . minimise_criterion : bool = minimise_criterion self . criterion = criterion self . model_fit_kwargs = model_fit_kwargs or {} if model_fit_kwargs : # check that these are valid kwargs for model fit sig = signature ( self . model . fit ) try : sig . bind_partial ( ** self . model_fit_kwargs ) except TypeError : raise Exception ( \"Invalid arguments for model.fit\" ) self . model_evaluate_kwargs = model_evaluate_kwargs or {} if model_evaluate_kwargs : # check that these are valid kwargs for model evaluate sig = signature ( self . model . evaluate ) try : sig . bind_partial ( ** self . model_evaluate_kwargs ) except TypeError : raise Exception ( \"Invalid arguments for model.evaluate\" ) self . vote_score : float = self . test ( self . train_loader ) def mli_propose_weights ( self ) -> Weights : \"\"\" Trains model on training set and returns new weights after training - Current model is reverted to original state after training :return: Weights after training \"\"\" current_weights = self . mli_get_current_weights () self . train () new_weights = self . mli_get_current_weights () self . set_weights ( current_weights ) return new_weights def mli_test_weights ( self , weights : Weights ) -> ProposedWeights : \"\"\" Tests given weights on training and test set and returns weights with score values :param weights: Weights to be tested :return: ProposedWeights - Weights with vote and test score \"\"\" current_weights = self . mli_get_current_weights () self . set_weights ( weights ) vote_score = self . test ( self . train_loader ) if self . test_loader : test_score = self . test ( self . test_loader ) else : test_score = 0 vote = self . vote ( vote_score ) self . set_weights ( current_weights ) return ProposedWeights ( weights = weights , vote_score = vote_score , test_score = test_score , vote = vote ) def vote ( self , new_score ) -> bool : \"\"\" Compares current model score with proposed model score and returns vote :param new_score: Proposed score :return: bool positive or negative vote \"\"\" if self . minimise_criterion : return new_score <= self . vote_score else : return new_score >= self . vote_score def mli_accept_weights ( self , weights : Weights ): \"\"\" Updates the model with the proposed set of weights :param weights: The new weights \"\"\" self . set_weights ( weights ) self . vote_score = self . test ( self . train_loader ) def mli_get_current_weights ( self ) -> Weights : \"\"\" :return: The current weights of the model \"\"\" return Weights ( weights = self . model . get_weights ()) def set_weights ( self , weights : Weights ): \"\"\" Rewrites weight of current model :param weights: Weights to be stored \"\"\" self . model . set_weights ( weights . weights ) def train ( self ): \"\"\" Trains the model on the training dataset \"\"\" self . model . fit ( self . train_loader , ** self . model_fit_kwargs ) def test ( self , loader : tf . data . Dataset ) -> float : \"\"\" Tests performance of the model on specified dataset :param loader: Dataset for testing :return: Value of performance metric \"\"\" result = self . model . evaluate ( x = loader , return_dict = True , ** self . model_evaluate_kwargs ) return result [ self . criterion ] We create a set of KerasLearners by passing in the model and the datasets: all_learner_models = [] for i in range ( n_learners ): all_learner_models . append ( KerasLearner ( model = get_model (), train_loader = train_datasets [ i ], test_loader = test_datasets [ i ], criterion = \"sparse_categorical_accuracy\" , minimise_criterion = False , model_evaluate_kwargs = { \"steps\" : vote_batches }, )) Then we give all the models the same weights to start off with: set_equal_weights ( all_learner_models ) And then we can move on to the final stage, which is training with Collective Learning. The function collective_learning_round performs one round of collective learning. One learner is selected to train and propose an update. The other learners vote on the update, and if the vote passes then the update is accepted. Then a new round begins. # Train the model using Collective Learning results = Results () results . data . append ( initial_result ( all_learner_models )) for round in range ( n_rounds ): results . data . append ( collective_learning_round ( all_learner_models , vote_threshold , round ) ) plot_results ( results , n_learners , block = False , score_name = all_learner_models [ 0 ] . criterion ) plot_votes ( results , block = False ) plot_results ( results , n_learners , block = False , score_name = all_learner_models [ 0 ] . criterion ) plot_votes ( results , block = True ) Simple!","title":"Using collective learning with keras"},{"location":"intro_tutorial_mli/","text":"Using collective learning \u00b6 This tutorial is a simple guide to trying out the collective learning protocol with your own machine learning code. Everything runs locally. The most flexible way to use the collective learning backends is to make a class that implements the Collective Learning MachineLearningInterface defined in ml_interface.py . This tutorial will walk through implementing the MachineLearningInterface . If you're already using keras or pytorch you might find it easier to use the KerasLearner or Pytorchlearner classes. See the other tutorials for details of how to do that. The MachineLearningInterface \u00b6 import abc from typing import Optional , Any , Dict from pydantic import BaseModel class Weights ( BaseModel ): weights : Any class ProposedWeights ( BaseModel ): weights : Weights vote_score : float test_score : float vote : bool evaluation_results : Optional [ Dict ] = None class MachineLearningInterface ( abc . ABC ): @abc . abstractmethod def mli_propose_weights ( self ) -> Weights : \"\"\" Trains the model. Returns new weights. Does not change the current weights of the model. \"\"\" pass @abc . abstractmethod def mli_test_weights ( self , weights : Weights ) -> ProposedWeights : \"\"\" Tests the proposed weights and fills in the rest of the fields \"\"\" @abc . abstractmethod def mli_accept_weights ( self , weights : Weights ): \"\"\" Updates the model with the proposed set of weights :param weights: The new weights \"\"\" pass @abc . abstractmethod def mli_get_current_weights ( self ) -> Weights : \"\"\" Returns the current weights of the model \"\"\" pass There are four methods that need to be implemented: propose_weights causes the model to do some training and then return a new set of weights that are propsed to the other learners. This method shouldn't charge the current weights of the model - that only happens when accept_weights is called. test_weights - the models takes some new weights and returns a vote on whether the new weights are an improvement. As in propse_weights, this shouldn't change the current weights of the model - that only happens when accept_weights is called. accept_weights - the models accepts some weights that have been voted on and approved by the set of learners. The old weighs of the model are discarded and replaced by the new weights. current_weights should return the current weights of the model. Implementation for fraud detection task \u00b6 Here is the class that implements the MachineLearningInterface for the task of detecting fraud in bank transactions. class FraudSklearnLearner ( MachineLearningInterface ): def __init__ ( self , train_data , train_labels , test_data , test_labels , batch_size : int = 10000 , steps_per_round : int = 1 ): self . steps_per_round = steps_per_round self . batch_size = batch_size self . train_data = train_data self . train_labels = train_labels self . test_data = test_data self . test_labels = test_labels self . class_labels = np . unique ( train_labels ) self . train_sampler = infinite_batch_sampler ( train_data . shape [ 0 ], batch_size ) self . model = SGDClassifier ( max_iter = 1 , verbose = 0 , loss = \"modified_huber\" ) self . model . partial_fit ( self . train_data [ 0 : 1 ], self . train_labels [ 0 : 1 ], classes = self . class_labels ) # this needs to be called before predict self . vote_score = self . test ( self . train_data , self . train_labels ) def mli_propose_weights ( self ) -> Weights : current_weights = self . mli_get_current_weights () for i in range ( self . steps_per_round ): batch_indices = next ( self . train_sampler ) train_data = self . train_data [ batch_indices ] train_labels = self . train_labels [ batch_indices ] self . model . partial_fit ( train_data , train_labels , classes = self . class_labels ) new_weights = self . mli_get_current_weights () self . set_weights ( current_weights ) return new_weights def mli_test_weights ( self , weights : Weights ) -> ProposedWeights : current_weights = self . mli_get_current_weights () self . set_weights ( weights ) vote_score = self . test ( self . train_data , self . train_labels ) test_score = self . test ( self . test_data , self . test_labels ) vote = self . vote_score <= vote_score self . set_weights ( current_weights ) return ProposedWeights ( weights = weights , vote_score = vote_score , test_score = test_score , vote = vote ) def mli_accept_weights ( self , weights : Weights ): self . set_weights ( weights ) self . vote_score = self . test ( self . train_data , self . train_labels ) def mli_get_current_weights ( self ): # return Weights(weights=copy.deepcopy(self.model)) return Weights ( weights = dict ( coef_ = self . model . coef_ , intercept_ = self . model . intercept_ )) def set_weights ( self , weights : Weights ): # self.model = weights.weights self . model . coef_ = weights . weights [ 'coef_' ] self . model . intercept_ = weights . weights [ 'intercept_' ] def test ( self , data , labels ): try : return self . model . score ( data , labels ) except sklearn . exceptions . NotFittedError : return 0 Let's step through this and see how it works. The propose_weights method saves the current weights of the model. Then it performs some training of the model, and gets the new weights. It returns the new weights, and resets the model weights to be the old weights. def mli_propose_weights ( self ) -> Weights : current_weights = self . mli_get_current_weights () for i in range ( self . steps_per_round ): batch_indices = next ( self . train_sampler ) train_data = self . train_data [ batch_indices ] train_labels = self . train_labels [ batch_indices ] self . model . partial_fit ( train_data , train_labels , classes = self . class_labels ) new_weights = self . mli_get_current_weights () self . set_weights ( current_weights ) return new_weights The test_weights method takes as a parameter the proposed weights that it needs to vote on. It saves the current weights of the model, and then sets the model weights to be the proposed weights. It tests the model and votes based on whether the score that it is monitoring has improved. The vote score can be any metric that you like. You could use loss, accuracy, mean squared error or any custom metric. If the vote score is the loss then the model would only vote True if the score has decreased. Here's we're using accuracy, so the vote is true if the score increases. This method then resets the weights to the old values and returns the vote along with some scores for monitoring purposes. def mli_test_weights ( self , weights : Weights ) -> ProposedWeights : current_weights = self . mli_get_current_weights () self . set_weights ( weights ) vote_score = self . test ( self . train_data , self . train_labels ) test_score = self . test ( self . test_data , self . test_labels ) vote = self . vote_score <= vote_score self . set_weights ( current_weights ) return ProposedWeights ( weights = weights , vote_score = vote_score , test_score = test_score , vote = vote ) The accept_weights method sets the weights of the model to be the new weights. It also updates the vote score to be the current performance. Note You could implement a cache here. These weights will already have been tested in test_weights, so the vote score could be retrieved from the cache instead of recomputed. def mli_accept_weights ( self , weights : Weights ): self . set_weights ( weights ) self . vote_score = self . test ( self . train_data , self . train_labels ) The final method is the simplest - get_current_weights just returns the current weights of the model. These weights are wrapped inside a Weights object. def mli_get_current_weights ( self ): return Weights ( weights = dict ( coef_ = self . model . coef_ , intercept_ = self . model . intercept_ )) The rest of the example \u00b6 The data is loaded and preprocessed and then split into equal parts for each learner. Then a list of FraudLearner instances is created, each with its own dataset. all_learner_models = [] for i in range ( n_learners ): all_learner_models . append ( FraudLearner ( train_data = learner_train_data [ i ], train_labels = learner_train_labels [ i ], test_data = learner_test_data [ i ], test_labels = learner_test_labels [ i ] )) Then we give all the models the same weights to start off with: set_equal_weights ( all_learner_models ) And then we can move on to the final stage, which is training with Collective Learning. The function collective_learning_round performs one round of collective learning. One learner is selected to train and propose an update. The other learners vote on the update, and if the vote passes then the update is accepted. Then a new round begins. # Train the model using Collective Learning results = Results () results . data . append ( initial_result ( all_learner_models )) for round in range ( n_rounds ): results . data . append ( collective_learning_round ( all_learner_models , vote_threshold , round ) ) plot_results ( results , n_learners , block = False , score_name = all_learner_models [ 0 ] . criterion ) plot_votes ( results , block = False ) plot_results ( results , n_learners , block = False , score_name = all_learner_models [ 0 ] . criterion ) plot_votes ( results , block = True )","title":"The MachineLearningInterface"},{"location":"intro_tutorial_mli/#using-collective-learning","text":"This tutorial is a simple guide to trying out the collective learning protocol with your own machine learning code. Everything runs locally. The most flexible way to use the collective learning backends is to make a class that implements the Collective Learning MachineLearningInterface defined in ml_interface.py . This tutorial will walk through implementing the MachineLearningInterface . If you're already using keras or pytorch you might find it easier to use the KerasLearner or Pytorchlearner classes. See the other tutorials for details of how to do that.","title":"Using collective learning"},{"location":"intro_tutorial_mli/#the-machinelearninginterface","text":"import abc from typing import Optional , Any , Dict from pydantic import BaseModel class Weights ( BaseModel ): weights : Any class ProposedWeights ( BaseModel ): weights : Weights vote_score : float test_score : float vote : bool evaluation_results : Optional [ Dict ] = None class MachineLearningInterface ( abc . ABC ): @abc . abstractmethod def mli_propose_weights ( self ) -> Weights : \"\"\" Trains the model. Returns new weights. Does not change the current weights of the model. \"\"\" pass @abc . abstractmethod def mli_test_weights ( self , weights : Weights ) -> ProposedWeights : \"\"\" Tests the proposed weights and fills in the rest of the fields \"\"\" @abc . abstractmethod def mli_accept_weights ( self , weights : Weights ): \"\"\" Updates the model with the proposed set of weights :param weights: The new weights \"\"\" pass @abc . abstractmethod def mli_get_current_weights ( self ) -> Weights : \"\"\" Returns the current weights of the model \"\"\" pass There are four methods that need to be implemented: propose_weights causes the model to do some training and then return a new set of weights that are propsed to the other learners. This method shouldn't charge the current weights of the model - that only happens when accept_weights is called. test_weights - the models takes some new weights and returns a vote on whether the new weights are an improvement. As in propse_weights, this shouldn't change the current weights of the model - that only happens when accept_weights is called. accept_weights - the models accepts some weights that have been voted on and approved by the set of learners. The old weighs of the model are discarded and replaced by the new weights. current_weights should return the current weights of the model.","title":"The MachineLearningInterface"},{"location":"intro_tutorial_mli/#implementation-for-fraud-detection-task","text":"Here is the class that implements the MachineLearningInterface for the task of detecting fraud in bank transactions. class FraudSklearnLearner ( MachineLearningInterface ): def __init__ ( self , train_data , train_labels , test_data , test_labels , batch_size : int = 10000 , steps_per_round : int = 1 ): self . steps_per_round = steps_per_round self . batch_size = batch_size self . train_data = train_data self . train_labels = train_labels self . test_data = test_data self . test_labels = test_labels self . class_labels = np . unique ( train_labels ) self . train_sampler = infinite_batch_sampler ( train_data . shape [ 0 ], batch_size ) self . model = SGDClassifier ( max_iter = 1 , verbose = 0 , loss = \"modified_huber\" ) self . model . partial_fit ( self . train_data [ 0 : 1 ], self . train_labels [ 0 : 1 ], classes = self . class_labels ) # this needs to be called before predict self . vote_score = self . test ( self . train_data , self . train_labels ) def mli_propose_weights ( self ) -> Weights : current_weights = self . mli_get_current_weights () for i in range ( self . steps_per_round ): batch_indices = next ( self . train_sampler ) train_data = self . train_data [ batch_indices ] train_labels = self . train_labels [ batch_indices ] self . model . partial_fit ( train_data , train_labels , classes = self . class_labels ) new_weights = self . mli_get_current_weights () self . set_weights ( current_weights ) return new_weights def mli_test_weights ( self , weights : Weights ) -> ProposedWeights : current_weights = self . mli_get_current_weights () self . set_weights ( weights ) vote_score = self . test ( self . train_data , self . train_labels ) test_score = self . test ( self . test_data , self . test_labels ) vote = self . vote_score <= vote_score self . set_weights ( current_weights ) return ProposedWeights ( weights = weights , vote_score = vote_score , test_score = test_score , vote = vote ) def mli_accept_weights ( self , weights : Weights ): self . set_weights ( weights ) self . vote_score = self . test ( self . train_data , self . train_labels ) def mli_get_current_weights ( self ): # return Weights(weights=copy.deepcopy(self.model)) return Weights ( weights = dict ( coef_ = self . model . coef_ , intercept_ = self . model . intercept_ )) def set_weights ( self , weights : Weights ): # self.model = weights.weights self . model . coef_ = weights . weights [ 'coef_' ] self . model . intercept_ = weights . weights [ 'intercept_' ] def test ( self , data , labels ): try : return self . model . score ( data , labels ) except sklearn . exceptions . NotFittedError : return 0 Let's step through this and see how it works. The propose_weights method saves the current weights of the model. Then it performs some training of the model, and gets the new weights. It returns the new weights, and resets the model weights to be the old weights. def mli_propose_weights ( self ) -> Weights : current_weights = self . mli_get_current_weights () for i in range ( self . steps_per_round ): batch_indices = next ( self . train_sampler ) train_data = self . train_data [ batch_indices ] train_labels = self . train_labels [ batch_indices ] self . model . partial_fit ( train_data , train_labels , classes = self . class_labels ) new_weights = self . mli_get_current_weights () self . set_weights ( current_weights ) return new_weights The test_weights method takes as a parameter the proposed weights that it needs to vote on. It saves the current weights of the model, and then sets the model weights to be the proposed weights. It tests the model and votes based on whether the score that it is monitoring has improved. The vote score can be any metric that you like. You could use loss, accuracy, mean squared error or any custom metric. If the vote score is the loss then the model would only vote True if the score has decreased. Here's we're using accuracy, so the vote is true if the score increases. This method then resets the weights to the old values and returns the vote along with some scores for monitoring purposes. def mli_test_weights ( self , weights : Weights ) -> ProposedWeights : current_weights = self . mli_get_current_weights () self . set_weights ( weights ) vote_score = self . test ( self . train_data , self . train_labels ) test_score = self . test ( self . test_data , self . test_labels ) vote = self . vote_score <= vote_score self . set_weights ( current_weights ) return ProposedWeights ( weights = weights , vote_score = vote_score , test_score = test_score , vote = vote ) The accept_weights method sets the weights of the model to be the new weights. It also updates the vote score to be the current performance. Note You could implement a cache here. These weights will already have been tested in test_weights, so the vote score could be retrieved from the cache instead of recomputed. def mli_accept_weights ( self , weights : Weights ): self . set_weights ( weights ) self . vote_score = self . test ( self . train_data , self . train_labels ) The final method is the simplest - get_current_weights just returns the current weights of the model. These weights are wrapped inside a Weights object. def mli_get_current_weights ( self ): return Weights ( weights = dict ( coef_ = self . model . coef_ , intercept_ = self . model . intercept_ ))","title":"Implementation for fraud detection task"},{"location":"intro_tutorial_mli/#the-rest-of-the-example","text":"The data is loaded and preprocessed and then split into equal parts for each learner. Then a list of FraudLearner instances is created, each with its own dataset. all_learner_models = [] for i in range ( n_learners ): all_learner_models . append ( FraudLearner ( train_data = learner_train_data [ i ], train_labels = learner_train_labels [ i ], test_data = learner_test_data [ i ], test_labels = learner_test_labels [ i ] )) Then we give all the models the same weights to start off with: set_equal_weights ( all_learner_models ) And then we can move on to the final stage, which is training with Collective Learning. The function collective_learning_round performs one round of collective learning. One learner is selected to train and propose an update. The other learners vote on the update, and if the vote passes then the update is accepted. Then a new round begins. # Train the model using Collective Learning results = Results () results . data . append ( initial_result ( all_learner_models )) for round in range ( n_rounds ): results . data . append ( collective_learning_round ( all_learner_models , vote_threshold , round ) ) plot_results ( results , n_learners , block = False , score_name = all_learner_models [ 0 ] . criterion ) plot_votes ( results , block = False ) plot_results ( results , n_learners , block = False , score_name = all_learner_models [ 0 ] . criterion ) plot_votes ( results , block = True )","title":"The rest of the example"},{"location":"intro_tutorial_pytorch/","text":"Using collective learning with pytorch \u00b6 This tutorial is a simple guide to trying out the collective learning protocol with your own machine learning code. Everything runs locally. The most flexible way to use the collective learning backends is to make a class that implements the Collective Learning MachineLearningInterface defined in ml_interface.py . For more details on how to use the MachineLearningInterface see here However, the simpler way is to use one of the helper classes that we have provided that implement most of the interface for popular ML libraries. In this tutorial we are going to walk through using the PytorchLearner . First we are going to define the model architecture, then we are going to load the data and configure the model, and then we will run Collective Learning. A standard script for machine learning with Pytorch looks like the one below from torchsummary import summary from torchvision import transforms , datasets import torch.utils.data import torch.nn as nn import torch.nn.functional as nn_func # define some constants batch_size = 64 seed = 42 n_rounds = 20 train_fraction = 0.9 learning_rate = 0.001 height = 28 width = 28 n_classes = 10 num_test_batches = 10 no_cuda = False cuda = not no_cuda and torch . cuda . is_available () device = torch . device ( \"cuda\" if cuda else \"cpu\" ) kwargs = { 'num_workers' : 1 , 'pin_memory' : True } if cuda else {} # Load the data data = datasets . MNIST ( '/tmp/mnist' , transform = transforms . ToTensor (), download = True ) n_train = int ( train_fraction * len ( data )) n_test = len ( data ) - n_train train_data , test_data = torch . utils . data . random_split ( data , [ n_train , n_test ]) train_dataloader = torch . utils . data . DataLoader ( train_data , batch_size = batch_size , shuffle = True , ** kwargs ) test_dataloader = torch . utils . data . DataLoader ( test_data , batch_size = batch_size , shuffle = True , ** kwargs ) # Define the model class Net ( nn . Module ): def __init__ ( self ): super ( Net , self ) . __init__ () self . conv1 = nn . Conv2d ( 1 , 20 , 5 , 1 ) self . conv2 = nn . Conv2d ( 20 , 50 , 5 , 1 ) self . fc1 = nn . Linear ( 4 * 4 * 50 , 500 ) self . fc2 = nn . Linear ( 500 , n_classes ) def forward ( self , x ): x = nn_func . relu ( self . conv1 ( x . view ( - 1 , 1 , height , width ))) x = nn_func . max_pool2d ( x , 2 , 2 ) x = nn_func . relu ( self . conv2 ( x )) x = nn_func . max_pool2d ( x , 2 , 2 ) x = x . view ( - 1 , 4 * 4 * 50 ) x = nn_func . relu ( self . fc1 ( x )) x = self . fc2 ( x ) return nn_func . log_softmax ( x , dim = 1 ) model = Net () opt = torch . optim . Adam ( model . parameters (), lr = learning_rate ) criterion = torch . nn . NLLLoss () # Train and evaluate the model for round in range ( n_rounds ): # train model model . train () for batch_idx , ( data , labels ) in enumerate ( train_dataloader ): opt . zero_grad () # Data needs to be on same device as model data = data . to ( device ) labels = labels . to ( device ) output = model ( data ) loss = criterion ( output , labels ) loss . backward () opt . step () # evaluate model model . eval () total_score = 0 all_labels = [] all_outputs = [] with torch . no_grad (): for batch_idx , ( data , labels ) in enumerate ( test_dataloader ): if batch_idx == num_test_batches : break data = data . to ( device ) labels = labels . to ( device ) output = model ( data ) total_score += criterion ( output , labels ) avg_loss = float ( total_score / ( num_test_batches * batch_size )) print ( f \"Average loss at round { round } is { avg_loss } \" ) There are three steps: Load the data Define the model Train the model In this tutorial we are going to see how to modify each step to use collective learning. We'll end up with code like this: from typing_extensions import TypedDict import torch.nn as nn import torch.nn.functional as nn_func import torch.utils.data from torchsummary import summary from torchvision import transforms , datasets from colearn.training import initial_result , collective_learning_round , set_equal_weights from colearn.utils.plot import ColearnPlot from colearn.utils.results import Results from colearn_pytorch.utils import categorical_accuracy from colearn_pytorch.pytorch_learner import PytorchLearner \"\"\" MNIST training example using PyTorch Used dataset: - MNIST is set of 60 000 black and white hand written digits images of size 28x28x1 in 10 classes What script does: - Loads MNIST dataset from torchvision.datasets - Randomly splits dataset between multiple learners - Does multiple rounds of learning process and displays plot with results \"\"\" # define some constants n_learners = 5 batch_size = 64 n_epochs = 20 vote_threshold = 0.5 train_fraction = 0.9 learning_rate = 0.001 height = 28 width = 28 n_classes = 10 vote_batches = 2 score_name = \"categorical accuracy\" no_cuda = False cuda = not no_cuda and torch . cuda . is_available () device = torch . device ( \"cuda\" if cuda else \"cpu\" ) DataloaderKwargs = TypedDict ( 'DataloaderKwargs' , { 'num_workers' : int , 'pin_memory' : bool }, total = False ) kwargs : DataloaderKwargs = { 'num_workers' : 1 , 'pin_memory' : True } if cuda else {} # Load the data and split for each learner. train_root = '/tmp/mnist' data = datasets . MNIST ( train_root , transform = transforms . ToTensor (), download = True ) n_train = int ( train_fraction * len ( data )) n_test = len ( data ) - n_train train_data , test_data = torch . utils . data . random_split ( data , [ n_train , n_test ]) data_split = [ len ( train_data ) // n_learners ] * n_learners learner_train_data = torch . utils . data . random_split ( train_data , data_split ) learner_train_dataloaders = [ torch . utils . data . DataLoader ( ds , batch_size = batch_size , shuffle = True , ** kwargs ) for ds in learner_train_data ] data_split = [ len ( test_data ) // n_learners ] * n_learners learner_test_data = torch . utils . data . random_split ( test_data , data_split ) learner_test_dataloaders = [ torch . utils . data . DataLoader ( ds , batch_size = batch_size , shuffle = True , ** kwargs ) for ds in learner_test_data ] # Define the model class Net ( nn . Module ): def __init__ ( self ): super ( Net , self ) . __init__ () self . conv1 = nn . Conv2d ( 1 , 20 , 5 , 1 ) self . conv2 = nn . Conv2d ( 20 , 50 , 5 , 1 ) self . fc1 = nn . Linear ( 4 * 4 * 50 , 500 ) self . fc2 = nn . Linear ( 500 , n_classes ) def forward ( self , x ): x = nn_func . relu ( self . conv1 ( x . view ( - 1 , 1 , height , width ))) x = nn_func . max_pool2d ( x , 2 , 2 ) x = nn_func . relu ( self . conv2 ( x )) x = nn_func . max_pool2d ( x , 2 , 2 ) x = x . view ( - 1 , 4 * 4 * 50 ) x = nn_func . relu ( self . fc1 ( x )) x = self . fc2 ( x ) return nn_func . log_softmax ( x , dim = 1 ) # Make n instances of PytorchLearner with model and torch dataloaders all_learner_models = [] for i in range ( n_learners ): model = Net () opt = torch . optim . Adam ( model . parameters (), lr = learning_rate ) learner = PytorchLearner ( model = model , train_loader = learner_train_dataloaders [ i ], test_loader = learner_test_dataloaders [ i ], device = device , optimizer = opt , criterion = torch . nn . NLLLoss (), num_test_batches = vote_batches , vote_criterion = categorical_accuracy , minimise_criterion = False ) all_learner_models . append ( learner ) # Ensure all learners starts with exactly same weights set_equal_weights ( all_learner_models ) summary ( all_learner_models [ 0 ] . model , input_size = ( width , height )) # Train the model using Collective Learning results = Results () results . data . append ( initial_result ( all_learner_models )) plot = ColearnPlot ( n_learners = n_learners , score_name = score_name ) for epoch in range ( n_epochs ): results . data . append ( collective_learning_round ( all_learner_models , vote_threshold , epoch ) ) plot . plot_results ( results ) plot . plot_votes ( results ) # Plot the final result with votes plot . plot_results ( results ) plot . plot_votes ( results , block = True ) print ( \"Colearn Example Finished!\" ) The first thing is to modify the data loading code. Each learner needs to have their own training and testing set from the data. This is easy to do with the pytorch random_split utility: data_split = [ len ( test_data ) // n_learners ] * n_learners learner_test_data = torch . utils . data . random_split ( test_data , data_split ) The model definition is the same as before. To use collective learning, we need to create an object that implements the MachineLearningInterface. To make it easier to use the MachineLearningInterface with pytorch, we've defined PytorchLearner . PytorchLearner implements standard training and evaluation routines as well as the MachineLearningInterface methods. from typing import Optional , Callable try : import torch except ImportError : raise Exception ( \"Pytorch is not installed. To use the pytorch \" \"add-ons please install colearn with `pip install colearn[pytorch]`.\" ) import torch.nn import torch.optim import torch.utils import torch.utils.data from torch.nn.modules.loss import _Loss from colearn.ml_interface import MachineLearningInterface , Weights , ProposedWeights _DEFAULT_DEVICE = torch . device ( \"cpu\" ) class PytorchLearner ( MachineLearningInterface ): \"\"\" Pytorch learner implementation of machine learning interface \"\"\" def __init__ ( self , model : torch . nn . Module , optimizer : torch . optim . Optimizer , train_loader : torch . utils . data . DataLoader , test_loader : Optional [ torch . utils . data . DataLoader ] = None , device = _DEFAULT_DEVICE , criterion : Optional [ _Loss ] = None , minimise_criterion = True , vote_criterion : Optional [ Callable [[ torch . Tensor , torch . Tensor ], float ]] = None , num_train_batches : Optional [ int ] = None , num_test_batches : Optional [ int ] = None ): \"\"\" :param model: Pytorch model used for training :param optimizer: Training optimizer :param train_loader: Train dataset :param test_loader: Optional test dataset - subset of training set will be used if not specified :param device: Pytorch device - CPU or GPU :param criterion: Loss function :param minimise_criterion: True to minimise value of criterion, False to maximise :param vote_criterion: Function to measure model performance for voting :param num_train_batches: Number of training batches :param num_test_batches: Number of testing batches \"\"\" # Model has to be on same device as data self . model : torch . nn . Module = model . to ( device ) self . optimizer : torch . optim . Optimizer = optimizer self . criterion = criterion self . train_loader : torch . utils . data . DataLoader = train_loader self . test_loader : Optional [ torch . utils . data . DataLoader ] = test_loader self . device = device self . num_train_batches = num_train_batches or len ( train_loader ) self . num_test_batches = num_test_batches self . minimise_criterion = minimise_criterion self . vote_criterion = vote_criterion self . vote_score = self . test ( self . train_loader ) def mli_get_current_weights ( self ) -> Weights : \"\"\" :return: The current weights of the model \"\"\" w = Weights ( weights = [ x . clone () for x in self . model . parameters ()]) return w def set_weights ( self , weights : Weights ): \"\"\" Rewrites weight of current model :param weights: Weights to be stored \"\"\" with torch . no_grad (): for new_param , old_param in zip ( weights . weights , self . model . parameters ()): old_param . set_ ( new_param ) def train ( self ): \"\"\" Trains the model on the training dataset \"\"\" self . model . train () for batch_idx , ( data , labels ) in enumerate ( self . train_loader ): if batch_idx == self . num_train_batches : break self . optimizer . zero_grad () # Data needs to be on same device as model data = data . to ( self . device ) labels = labels . to ( self . device ) output = self . model ( data ) loss = self . criterion ( output , labels ) loss . backward () self . optimizer . step () def mli_propose_weights ( self ) -> Weights : \"\"\" Trains model on training set and returns new weights after training - Current model is reverted to original state after training :return: Weights after training \"\"\" current_weights = self . mli_get_current_weights () self . train () new_weights = self . mli_get_current_weights () self . set_weights ( current_weights ) return new_weights def mli_test_weights ( self , weights : Weights ) -> ProposedWeights : \"\"\" Tests given weights on training and test set and returns weights with score values :param weights: Weights to be tested :return: ProposedWeights - Weights with vote and test score \"\"\" current_weights = self . mli_get_current_weights () self . set_weights ( weights ) vote_score = self . test ( self . train_loader ) if self . test_loader : test_score = self . test ( self . test_loader ) else : test_score = 0 vote = self . vote ( vote_score ) self . set_weights ( current_weights ) return ProposedWeights ( weights = weights , vote_score = vote_score , test_score = test_score , vote = vote ) def vote ( self , new_score ) -> bool : \"\"\" Compares current model score with proposed model score and returns vote :param new_score: Proposed score :return: bool positive or negative vote \"\"\" if self . minimise_criterion : return new_score <= self . vote_score else : return new_score >= self . vote_score def test ( self , loader : torch . utils . data . DataLoader ) -> float : \"\"\" Tests performance of the model on specified dataset :param loader: Dataset for testing :return: Value of performance metric \"\"\" if not self . criterion : raise Exception ( \"Criterion is unspecified so test method cannot be used\" ) self . model . eval () total_score = 0 all_labels = [] all_outputs = [] batch_idx = 0 with torch . no_grad (): for batch_idx , ( data , labels ) in enumerate ( loader ): if self . num_test_batches and batch_idx == self . num_test_batches : break data = data . to ( self . device ) labels = labels . to ( self . device ) output = self . model ( data ) if self . vote_criterion is not None : all_labels . append ( labels ) all_outputs . append ( output ) else : total_score += self . criterion ( output , labels ) . item () if batch_idx == 0 : raise Exception ( \"No batches in loader\" ) if self . vote_criterion is None : return float ( total_score / ( batch_idx * loader . batch_size )) # type: ignore[operator] else : return self . vote_criterion ( torch . cat ( all_outputs , dim = 0 ), torch . cat ( all_labels , dim = 0 )) def mli_accept_weights ( self , weights : Weights ): \"\"\" Updates the model with the proposed set of weights :param weights: The new weights \"\"\" self . set_weights ( weights ) self . vote_score = self . test ( self . train_loader ) We create a set of PytorchLearners by passing in the model and the datasets: all_learner_models = [] for i in range ( n_learners ): model = Net () opt = torch . optim . Adam ( model . parameters (), lr = learning_rate ) learner = PytorchLearner ( model = model , train_loader = learner_train_dataloaders [ i ], test_loader = learner_test_dataloaders [ i ], device = device , optimizer = opt , criterion = torch . nn . NLLLoss (), num_test_batches = vote_batches , vote_criterion = categorical_accuracy , minimise_criterion = False ) all_learner_models . append ( learner ) Then we give all the models the same weights to start off with: set_equal_weights ( all_learner_models ) And then we can move on to the final stage, which is training with Collective Learning. The function collective_learning_round performs one round of collective learning. One learner is selected to train and propose an update. The other learners vote on the update, and if the vote passes then the update is accepted. Then a new round begins. # Train the model using Collective Learning results = Results () results . data . append ( initial_result ( all_learner_models )) for round in range ( n_rounds ): results . data . append ( collective_learning_round ( all_learner_models , vote_threshold , round ) ) plot_results ( results , n_learners , score_name = score_name ) plot_votes ( results ) # Plot the final result with votes plot_results ( results , n_learners , score_name = score_name ) plot_votes ( results , block = True ) Simple!","title":"PyTorch"},{"location":"intro_tutorial_pytorch/#using-collective-learning-with-pytorch","text":"This tutorial is a simple guide to trying out the collective learning protocol with your own machine learning code. Everything runs locally. The most flexible way to use the collective learning backends is to make a class that implements the Collective Learning MachineLearningInterface defined in ml_interface.py . For more details on how to use the MachineLearningInterface see here However, the simpler way is to use one of the helper classes that we have provided that implement most of the interface for popular ML libraries. In this tutorial we are going to walk through using the PytorchLearner . First we are going to define the model architecture, then we are going to load the data and configure the model, and then we will run Collective Learning. A standard script for machine learning with Pytorch looks like the one below from torchsummary import summary from torchvision import transforms , datasets import torch.utils.data import torch.nn as nn import torch.nn.functional as nn_func # define some constants batch_size = 64 seed = 42 n_rounds = 20 train_fraction = 0.9 learning_rate = 0.001 height = 28 width = 28 n_classes = 10 num_test_batches = 10 no_cuda = False cuda = not no_cuda and torch . cuda . is_available () device = torch . device ( \"cuda\" if cuda else \"cpu\" ) kwargs = { 'num_workers' : 1 , 'pin_memory' : True } if cuda else {} # Load the data data = datasets . MNIST ( '/tmp/mnist' , transform = transforms . ToTensor (), download = True ) n_train = int ( train_fraction * len ( data )) n_test = len ( data ) - n_train train_data , test_data = torch . utils . data . random_split ( data , [ n_train , n_test ]) train_dataloader = torch . utils . data . DataLoader ( train_data , batch_size = batch_size , shuffle = True , ** kwargs ) test_dataloader = torch . utils . data . DataLoader ( test_data , batch_size = batch_size , shuffle = True , ** kwargs ) # Define the model class Net ( nn . Module ): def __init__ ( self ): super ( Net , self ) . __init__ () self . conv1 = nn . Conv2d ( 1 , 20 , 5 , 1 ) self . conv2 = nn . Conv2d ( 20 , 50 , 5 , 1 ) self . fc1 = nn . Linear ( 4 * 4 * 50 , 500 ) self . fc2 = nn . Linear ( 500 , n_classes ) def forward ( self , x ): x = nn_func . relu ( self . conv1 ( x . view ( - 1 , 1 , height , width ))) x = nn_func . max_pool2d ( x , 2 , 2 ) x = nn_func . relu ( self . conv2 ( x )) x = nn_func . max_pool2d ( x , 2 , 2 ) x = x . view ( - 1 , 4 * 4 * 50 ) x = nn_func . relu ( self . fc1 ( x )) x = self . fc2 ( x ) return nn_func . log_softmax ( x , dim = 1 ) model = Net () opt = torch . optim . Adam ( model . parameters (), lr = learning_rate ) criterion = torch . nn . NLLLoss () # Train and evaluate the model for round in range ( n_rounds ): # train model model . train () for batch_idx , ( data , labels ) in enumerate ( train_dataloader ): opt . zero_grad () # Data needs to be on same device as model data = data . to ( device ) labels = labels . to ( device ) output = model ( data ) loss = criterion ( output , labels ) loss . backward () opt . step () # evaluate model model . eval () total_score = 0 all_labels = [] all_outputs = [] with torch . no_grad (): for batch_idx , ( data , labels ) in enumerate ( test_dataloader ): if batch_idx == num_test_batches : break data = data . to ( device ) labels = labels . to ( device ) output = model ( data ) total_score += criterion ( output , labels ) avg_loss = float ( total_score / ( num_test_batches * batch_size )) print ( f \"Average loss at round { round } is { avg_loss } \" ) There are three steps: Load the data Define the model Train the model In this tutorial we are going to see how to modify each step to use collective learning. We'll end up with code like this: from typing_extensions import TypedDict import torch.nn as nn import torch.nn.functional as nn_func import torch.utils.data from torchsummary import summary from torchvision import transforms , datasets from colearn.training import initial_result , collective_learning_round , set_equal_weights from colearn.utils.plot import ColearnPlot from colearn.utils.results import Results from colearn_pytorch.utils import categorical_accuracy from colearn_pytorch.pytorch_learner import PytorchLearner \"\"\" MNIST training example using PyTorch Used dataset: - MNIST is set of 60 000 black and white hand written digits images of size 28x28x1 in 10 classes What script does: - Loads MNIST dataset from torchvision.datasets - Randomly splits dataset between multiple learners - Does multiple rounds of learning process and displays plot with results \"\"\" # define some constants n_learners = 5 batch_size = 64 n_epochs = 20 vote_threshold = 0.5 train_fraction = 0.9 learning_rate = 0.001 height = 28 width = 28 n_classes = 10 vote_batches = 2 score_name = \"categorical accuracy\" no_cuda = False cuda = not no_cuda and torch . cuda . is_available () device = torch . device ( \"cuda\" if cuda else \"cpu\" ) DataloaderKwargs = TypedDict ( 'DataloaderKwargs' , { 'num_workers' : int , 'pin_memory' : bool }, total = False ) kwargs : DataloaderKwargs = { 'num_workers' : 1 , 'pin_memory' : True } if cuda else {} # Load the data and split for each learner. train_root = '/tmp/mnist' data = datasets . MNIST ( train_root , transform = transforms . ToTensor (), download = True ) n_train = int ( train_fraction * len ( data )) n_test = len ( data ) - n_train train_data , test_data = torch . utils . data . random_split ( data , [ n_train , n_test ]) data_split = [ len ( train_data ) // n_learners ] * n_learners learner_train_data = torch . utils . data . random_split ( train_data , data_split ) learner_train_dataloaders = [ torch . utils . data . DataLoader ( ds , batch_size = batch_size , shuffle = True , ** kwargs ) for ds in learner_train_data ] data_split = [ len ( test_data ) // n_learners ] * n_learners learner_test_data = torch . utils . data . random_split ( test_data , data_split ) learner_test_dataloaders = [ torch . utils . data . DataLoader ( ds , batch_size = batch_size , shuffle = True , ** kwargs ) for ds in learner_test_data ] # Define the model class Net ( nn . Module ): def __init__ ( self ): super ( Net , self ) . __init__ () self . conv1 = nn . Conv2d ( 1 , 20 , 5 , 1 ) self . conv2 = nn . Conv2d ( 20 , 50 , 5 , 1 ) self . fc1 = nn . Linear ( 4 * 4 * 50 , 500 ) self . fc2 = nn . Linear ( 500 , n_classes ) def forward ( self , x ): x = nn_func . relu ( self . conv1 ( x . view ( - 1 , 1 , height , width ))) x = nn_func . max_pool2d ( x , 2 , 2 ) x = nn_func . relu ( self . conv2 ( x )) x = nn_func . max_pool2d ( x , 2 , 2 ) x = x . view ( - 1 , 4 * 4 * 50 ) x = nn_func . relu ( self . fc1 ( x )) x = self . fc2 ( x ) return nn_func . log_softmax ( x , dim = 1 ) # Make n instances of PytorchLearner with model and torch dataloaders all_learner_models = [] for i in range ( n_learners ): model = Net () opt = torch . optim . Adam ( model . parameters (), lr = learning_rate ) learner = PytorchLearner ( model = model , train_loader = learner_train_dataloaders [ i ], test_loader = learner_test_dataloaders [ i ], device = device , optimizer = opt , criterion = torch . nn . NLLLoss (), num_test_batches = vote_batches , vote_criterion = categorical_accuracy , minimise_criterion = False ) all_learner_models . append ( learner ) # Ensure all learners starts with exactly same weights set_equal_weights ( all_learner_models ) summary ( all_learner_models [ 0 ] . model , input_size = ( width , height )) # Train the model using Collective Learning results = Results () results . data . append ( initial_result ( all_learner_models )) plot = ColearnPlot ( n_learners = n_learners , score_name = score_name ) for epoch in range ( n_epochs ): results . data . append ( collective_learning_round ( all_learner_models , vote_threshold , epoch ) ) plot . plot_results ( results ) plot . plot_votes ( results ) # Plot the final result with votes plot . plot_results ( results ) plot . plot_votes ( results , block = True ) print ( \"Colearn Example Finished!\" ) The first thing is to modify the data loading code. Each learner needs to have their own training and testing set from the data. This is easy to do with the pytorch random_split utility: data_split = [ len ( test_data ) // n_learners ] * n_learners learner_test_data = torch . utils . data . random_split ( test_data , data_split ) The model definition is the same as before. To use collective learning, we need to create an object that implements the MachineLearningInterface. To make it easier to use the MachineLearningInterface with pytorch, we've defined PytorchLearner . PytorchLearner implements standard training and evaluation routines as well as the MachineLearningInterface methods. from typing import Optional , Callable try : import torch except ImportError : raise Exception ( \"Pytorch is not installed. To use the pytorch \" \"add-ons please install colearn with `pip install colearn[pytorch]`.\" ) import torch.nn import torch.optim import torch.utils import torch.utils.data from torch.nn.modules.loss import _Loss from colearn.ml_interface import MachineLearningInterface , Weights , ProposedWeights _DEFAULT_DEVICE = torch . device ( \"cpu\" ) class PytorchLearner ( MachineLearningInterface ): \"\"\" Pytorch learner implementation of machine learning interface \"\"\" def __init__ ( self , model : torch . nn . Module , optimizer : torch . optim . Optimizer , train_loader : torch . utils . data . DataLoader , test_loader : Optional [ torch . utils . data . DataLoader ] = None , device = _DEFAULT_DEVICE , criterion : Optional [ _Loss ] = None , minimise_criterion = True , vote_criterion : Optional [ Callable [[ torch . Tensor , torch . Tensor ], float ]] = None , num_train_batches : Optional [ int ] = None , num_test_batches : Optional [ int ] = None ): \"\"\" :param model: Pytorch model used for training :param optimizer: Training optimizer :param train_loader: Train dataset :param test_loader: Optional test dataset - subset of training set will be used if not specified :param device: Pytorch device - CPU or GPU :param criterion: Loss function :param minimise_criterion: True to minimise value of criterion, False to maximise :param vote_criterion: Function to measure model performance for voting :param num_train_batches: Number of training batches :param num_test_batches: Number of testing batches \"\"\" # Model has to be on same device as data self . model : torch . nn . Module = model . to ( device ) self . optimizer : torch . optim . Optimizer = optimizer self . criterion = criterion self . train_loader : torch . utils . data . DataLoader = train_loader self . test_loader : Optional [ torch . utils . data . DataLoader ] = test_loader self . device = device self . num_train_batches = num_train_batches or len ( train_loader ) self . num_test_batches = num_test_batches self . minimise_criterion = minimise_criterion self . vote_criterion = vote_criterion self . vote_score = self . test ( self . train_loader ) def mli_get_current_weights ( self ) -> Weights : \"\"\" :return: The current weights of the model \"\"\" w = Weights ( weights = [ x . clone () for x in self . model . parameters ()]) return w def set_weights ( self , weights : Weights ): \"\"\" Rewrites weight of current model :param weights: Weights to be stored \"\"\" with torch . no_grad (): for new_param , old_param in zip ( weights . weights , self . model . parameters ()): old_param . set_ ( new_param ) def train ( self ): \"\"\" Trains the model on the training dataset \"\"\" self . model . train () for batch_idx , ( data , labels ) in enumerate ( self . train_loader ): if batch_idx == self . num_train_batches : break self . optimizer . zero_grad () # Data needs to be on same device as model data = data . to ( self . device ) labels = labels . to ( self . device ) output = self . model ( data ) loss = self . criterion ( output , labels ) loss . backward () self . optimizer . step () def mli_propose_weights ( self ) -> Weights : \"\"\" Trains model on training set and returns new weights after training - Current model is reverted to original state after training :return: Weights after training \"\"\" current_weights = self . mli_get_current_weights () self . train () new_weights = self . mli_get_current_weights () self . set_weights ( current_weights ) return new_weights def mli_test_weights ( self , weights : Weights ) -> ProposedWeights : \"\"\" Tests given weights on training and test set and returns weights with score values :param weights: Weights to be tested :return: ProposedWeights - Weights with vote and test score \"\"\" current_weights = self . mli_get_current_weights () self . set_weights ( weights ) vote_score = self . test ( self . train_loader ) if self . test_loader : test_score = self . test ( self . test_loader ) else : test_score = 0 vote = self . vote ( vote_score ) self . set_weights ( current_weights ) return ProposedWeights ( weights = weights , vote_score = vote_score , test_score = test_score , vote = vote ) def vote ( self , new_score ) -> bool : \"\"\" Compares current model score with proposed model score and returns vote :param new_score: Proposed score :return: bool positive or negative vote \"\"\" if self . minimise_criterion : return new_score <= self . vote_score else : return new_score >= self . vote_score def test ( self , loader : torch . utils . data . DataLoader ) -> float : \"\"\" Tests performance of the model on specified dataset :param loader: Dataset for testing :return: Value of performance metric \"\"\" if not self . criterion : raise Exception ( \"Criterion is unspecified so test method cannot be used\" ) self . model . eval () total_score = 0 all_labels = [] all_outputs = [] batch_idx = 0 with torch . no_grad (): for batch_idx , ( data , labels ) in enumerate ( loader ): if self . num_test_batches and batch_idx == self . num_test_batches : break data = data . to ( self . device ) labels = labels . to ( self . device ) output = self . model ( data ) if self . vote_criterion is not None : all_labels . append ( labels ) all_outputs . append ( output ) else : total_score += self . criterion ( output , labels ) . item () if batch_idx == 0 : raise Exception ( \"No batches in loader\" ) if self . vote_criterion is None : return float ( total_score / ( batch_idx * loader . batch_size )) # type: ignore[operator] else : return self . vote_criterion ( torch . cat ( all_outputs , dim = 0 ), torch . cat ( all_labels , dim = 0 )) def mli_accept_weights ( self , weights : Weights ): \"\"\" Updates the model with the proposed set of weights :param weights: The new weights \"\"\" self . set_weights ( weights ) self . vote_score = self . test ( self . train_loader ) We create a set of PytorchLearners by passing in the model and the datasets: all_learner_models = [] for i in range ( n_learners ): model = Net () opt = torch . optim . Adam ( model . parameters (), lr = learning_rate ) learner = PytorchLearner ( model = model , train_loader = learner_train_dataloaders [ i ], test_loader = learner_test_dataloaders [ i ], device = device , optimizer = opt , criterion = torch . nn . NLLLoss (), num_test_batches = vote_batches , vote_criterion = categorical_accuracy , minimise_criterion = False ) all_learner_models . append ( learner ) Then we give all the models the same weights to start off with: set_equal_weights ( all_learner_models ) And then we can move on to the final stage, which is training with Collective Learning. The function collective_learning_round performs one round of collective learning. One learner is selected to train and propose an update. The other learners vote on the update, and if the vote passes then the update is accepted. Then a new round begins. # Train the model using Collective Learning results = Results () results . data . append ( initial_result ( all_learner_models )) for round in range ( n_rounds ): results . data . append ( collective_learning_round ( all_learner_models , vote_threshold , round ) ) plot_results ( results , n_learners , score_name = score_name ) plot_votes ( results ) # Plot the final result with votes plot_results ( results , n_learners , score_name = score_name ) plot_votes ( results , block = True ) Simple!","title":"Using collective learning with pytorch"},{"location":"tasks/","text":"1. CIFAR10 dataset \u00b6 1.1. Information and installation \u00b6 1.1.1. Information about the dataset \u00b6 The CIFAR-10 dataset consists of 60000 32x32x3 colour images in 10 classes, with 6000 images per class. The 10 different classes represent airplanes, cars, birds, cats, deer, dogs, frogs, horses, ships, and trucks Input for NN are raw 32x32 3 channels GRB images NN output is distribution of probabilities for each class i.e. 10 values that sums up to 1 Code folder: here Invoke parameter: -t CIFAR10 1.1.2. Requirements \u00b6 Cifar dataset is loaded from tensorflow.keras.datasets.cifar10 and no stored data are required 1.2. Models \u00b6 1.2.1. CIFAR10Conv Keras model \u00b6 _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= Input (InputLayer) (32, 32, 3) 0 _________________________________________________________________ Conv1_1 (Conv2D) (32, 32, 64) 1792 bn1_1 (BatchNormalization) (32, 32, 64) 256 Conv1_2 (Conv2D) (32, 32, 64) 36928 bn1_2 (BatchNormalization) (32, 32, 64) 256 pool1 (MaxPooling2D) (16, 16, 64) 0 _________________________________________________________________ Conv2_1 (Conv2D) (16, 16, 128 73856 bn2_1 (BatchNormalization) (16, 16, 128 512 Conv2_2 (Conv2D) (16, 16, 128 147584 bn2_2 (BatchNormalization) (16, 16, 128 512 pool2 (MaxPooling2D) (8, 8, 128) 0 _________________________________________________________________ Conv3_1 (Conv2D) (8, 8, 256) 295168 bn3_1 (BatchNormalization) (8, 8, 256) 1024 Conv3_2 (Conv2D) (8, 8, 256) 590080 bn3_2 (BatchNormalization) (8, 8, 256) 1024 Conv3_3 (Conv2D) (8, 8, 256) 590080 bn3_3 (BatchNormalization) (8, 8, 256) 1024 _________________________________________________________________ flatten (Flatten) (16384) 0 fc1 (Dense) (100) 1638500 fc2 (Dense) (10) 1010 ================================================================= Total params: 3,379,606 Trainable params: 3,377,302 Non-trainable params: 2,304 _________________________________________________________________ 1.2.2. CIFAR10Conv2 Keras model \u00b6 _________________________________________________________ Layer (type) Output Shape Param # ========================================================= Input (InputLayer) (32, 32, 3) 0 _________________________________________________________ Conv1_1 (Conv2D) (32, 32, 32) 896 Conv1_2 (Conv2D) (32, 32, 32) 9248 pool1 (MaxPooling2D) (16, 16, 32) 0 _________________________________________________________ Conv2_1 (Conv2D) (16, 16, 64) 18496 Conv2_2 (Conv2D) (16, 16, 64) 36928 pool2 (MaxPooling2D) (8, 8, 64) 0 _________________________________________________________ Conv3_1 (Conv2D) (8, 8, 128) 73856 Conv3_2 (Conv2D) (8, 8, 128) 147584 pool3 (MaxPooling2D) (4, 4, 128) 0 _________________________________________________________ flatten (Flatten) (2048) 0 fc1 (Dense) (128) 262272 fc2 (Dense) (10) 1290 ========================================================= Total params: 550,570 Trainable params: 550,570 Non-trainable params: 0 _________________________________________________________ 1.2.3. CIFAR10Resnet50 Keras model \u00b6 ________________________________________________________ Layer (type) Output Shape Param # ======================================================== Input (InputLayer) (32, 32, 3)] 0 ________________________________________________________ resnet50 (Model) (1, 1, 2048) 23587712 ________________________________________________________ Global_average_pooling2d (2048) 0 flatten (Flatten) (2048) 0 fc1 (Dense) (10) 20490 ======================================================== Total params: 23,608,202 Trainable params: 23,555,082 Non-trainable params: 53,120 ________________________________________________________ 2. Covid X-RAY dataset \u00b6 2.1. Information and installation \u00b6 2.1.1. Information about the dataset \u00b6 The Covid X-Ray dataset consists of grayscale images, there are 478 covid images and 203 normal images. To increase the number of images normal/pneumonia dataset is added Final dataset, which is a combination of two previously mentioned datasets, contains 1434 images, 478 images for each class. Images are cropped and resized to 512x512 pixel and spatial domain (Texture, GLDM, GLCM) and frequency domain (FFT and Wavelet) features are used to create 256 dimensional vector representation of each image. PCA is applied after to reduce dimensionality to 64 values which represents the first 64 highest eigenvalues of the covariance matrix. Input for NN are 64 values for each image NN output is distribution of probabilities for each class i.e. 3 values Code folder: here Invoke parameter: -t COVID 2.1.2 Requirements \u00b6 Download Covid dataset: here Download pneumonia dataset: here 2.2. Models \u00b6 2.2.1. Covid XRAY Keras model \u00b6 _________________________________________________________ Layer (type) Output Shape Param # ========================================================= input_1 (InputLayer) (64) 0 _________________________________________________________ dense (Dense) (128) 8320 dropout (Dropout) (128) 0 _________________________________________________________ dense_1 (Dense) (16) 2064 dropout_1 (Dropout) (16) 0 _________________________________________________________ dense_2 (Dense) (3) 51 ========================================================= Total params: 10,435 Trainable params: 10,435 Non-trainable params: 0 _________________________________________________________ 3. FRAUD dataset \u00b6 3.1. Information and installation \u00b6 3.1.1. Information about the dataset \u00b6 EEE-CIS Fraud Detection, contains multiple files with credit card transactions Raw dataset files are automatically merged and pre-processed and input files for neural network are created X.csv with data - has 431 values for each transaction Y.csv with labels - v has 1 value for each transaction 0 = not a fraud 1 = fraud Code folder: here Invoke parameter: -t FRAUD 3.1.2. Requirements \u00b6 Download dataset: here 3.2. Models \u00b6 3.2.1. FraudDense1 Keras model \u00b6 _________________________________________________________ Layer (type) Output Shape Param # ========================================================= Input (InputLayer) (431) 0 _________________________________________________________ dense (Dense) (512) 221184 Batch_normalization (512) 2048 _________________________________________________________ dense_1 (Dense) (512) 262656 Batch_normalization_1 (512) 2048 _________________________________________________________ dense_2 (Dense) (512) 262656 Batch_normalization_2 (512) 2048 _________________________________________________________ fc1 (Dense) (1) 513 ========================================================= Total params: 753,153 Trainable params: 750,081 Non-trainable params: 3,072 _________________________________________________________ 3.2.2. FraudSVM Scikit-learn model \u00b6 Model is defined as SGDClassifier(max_iter=1, verbose=0, loss=\"modified_huber\") Which is support vector machine linear classifier 4. MNIST \u00b6 4.1. Information and installation \u00b6 4.1.1. Information about the dataset \u00b6 This is a dataset of 70,000 28x28x1 grayscale images of the 10 digits Input for NN are raw 28x28 1 channel images NN output is distribution of probabilities for each class i.e. 10 values that sums up to 1 Code folder: here Invoke parameter: -t MNIST 4.1.2 Requirements \u00b6 MNIST dataset is loaded from tensorflow.keras.datasets.cifar10 and no stored data are required 4.2. Models \u00b6 4.2.1. MNISTConv Keras model \u00b6 _________________________________________________________ Layer (type) Output Shape Param # ========================================================= Input (InputLayer) (28, 28, 1) 0 _________________________________________________________ Conv1_1 (Conv2D) (28, 28, 64) 640 bn1 (BatchNormalization) (28, 28, 64) 256 pool1 (MaxPooling2D) (14, 14, 64) 0 _________________________________________________________ Conv2_1 (Conv2D) (14, 14, 128) 73856 bn4 (BatchNormalization) (14, 14, 128) 512 pool2 (MaxPooling2D) (7, 7, 128) 0 _________________________________________________________ flatten (Flatten) (6272) 0 fc1 (Dense) (10) 62730 ========================================================= Total params: 137,994 Trainable params: 137,610 Non-trainable params: 384 _________________________________________________________ 4.2.2. MNIST Pytorch model \u00b6 --------------------------------------------------------- Layer (type) Output Shape Param # ========================================================= Input [28,28,1] 0 Conv2d-1 [20, 24, 24] 520 Conv2d-2 [50, 8, 8] 25,050 Linear-3 [500] 400,500 Linear-4 [10] 5,010 ========================================================= Total params: 431,080 Trainable params: 431,080 Non-trainable params: 0 --------------------------------------------------------- 4.2.3. MNISTSupermini Keras model \u00b6 ________________________________________________________________________________________ Layer (type) Output Shape Param # Connected to ======================================================================================== input_1 (InputLayer) (28, 28, 1) 0 ________________________________________________________________________________________ conv2d (Conv2D) (26, 26, 8) 80 input_1[0][0] Batch_normalization (26, 26, 8) 32 conv2d[0][0] Max_pooling2d (13, 13, 8) 0 batch_normalization[0][0] dropout (Dropout) (13, 13, 8) 0 max_pooling2d[0][0] ________________________________________________________________________________________ Separable_conv2d (11, 11, 26) 306 dropout[0][0] batch_normalization_1 (11, 11, 26) 104 separable_conv2d[0][0] dropout_1 (Dropout) (11, 11, 26) 0 batch_normalization_1[0][0] ________________________________________________________________________________________ Separable_conv2d_1 (11, 11, 26) 936 dropout_1[0][0] dropout_2[0][0] dropout_3[0][0] ________________________________________________________________________________________ Batch_normalization_2 (11, 11, 26) 104 separable_conv2d_1[0][0] dropout_2 (Dropout) (11, 11, 26) 0 batch_normalization_2[0][0] ________________________________________________________________________________________ Batch_normalization_3 (11, 11, 26) 104 separable_conv2d_1[1][0] dropout_3 (Dropout) (11, 11, 26) 0 batch_normalization_3[0][0] ________________________________________________________________________________________ Batch_normalization_4 (11, 11, 26) 104 separable_conv2d_1[2][0] dropout_4 (Dropout) (11, 11, 26) 0 batch_normalization_4[0][0] ________________________________________________________________________________________ Global_average_pooling2d (26) 0 dropout_4[0][0] dense (Dense) (16) 432 global_average_pooling2d[0][0] Batch_normalization_5 (16) 64 dense[0][0] dropout_5 (Dropout) (16) 0 batch_normalization_5[0][0] dense_1 (Dense) (10) 170 dropout_5[0][0] ======================================================================================== Total params: 2,436 Trainable params: 2,180 Non-trainable params: 256 ________________________________________________________________________________________ 5. Pneumonia XRAY \u00b6 5.1. Information and installation \u00b6 5.1.1. Information about the dataset \u00b6 The Chest X-Ray Images (Pneumonia) dataset consists of 5856 grayscale images of various sizes in 2 classes (normal/pneumonia). Labels are determined by folder name - NORMAL or PNEUMONIA Input for NN are raw resized 128x128 1 channel images NN output is distribution of probabilities for each class i.e. 2 values Code folder: here Invoke parameter: -t XRAY 5.1.2 Requirements \u00b6 Download dataset: here 5.2. Models \u00b6 5.2.1. XraySupermini Keras model \u00b6 _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= Input (InputLayer) [(128, 128, 1)] 0 _________________________________________________________________ Conv1_1 (Conv2D) (128, 128, 32) 320 _________________________________________________________________ bn1 (BatchNormalization) (128, 128, 32) 128 _________________________________________________________________ pool1 (MaxPooling2D) (32, 32, 32) 0 _________________________________________________________________ Conv2_1 (Conv2D) (32, 32, 64) 18496 _________________________________________________________________ bn2 (BatchNormalization) (32, 32, 64) 256 _________________________________________________________________ Global_max_pooling2d (64) 0 _________________________________________________________________ fc1 (Dense) (1) 65 ================================================================= Total params: 19,265 Trainable params: 19,073 Non-trainable params: 192 _________________________________________________________________ 5.2.2. XrayResnet50 Keras model \u00b6 _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= Input (InputLayer) [(128, 128, 1)] 0 _________________________________________________________________ resnet50 (Model) (4, 4, 2048) 23581440 _________________________________________________________________ global_average_pooling2d (2048) 0 _________________________________________________________________ flatten (Flatten) (2048) 0 _________________________________________________________________ fc1 (Dense) (1) 2049 ================================================================= Total params: 23,583,489 Trainable params: 23,530,369 Non-trainable params: 53,120 _________________________________________________________________ 5.2.3. XrayPretrainedResnet50 Keras model \u00b6 _____________________________________________________________________________________ Layer (type) Output Shape Param # Connected to ===================================================================================== Input (InputLayer) (128, 128, 1) 0 _____________________________________________________________________________________ concatenate (Concatenate) (128, 128, 3) 0 Input[0][0] Input[0][0] Input[0][0] _____________________________________________________________________________________ tf_op_layer_mul (128, 128, 3) 0 concatenate[0][0] tf_op_layer_strided_slice (128, 128, 3) 0 tf_op_layer_mul[0][0] tf_op_layer_BiasAdd (128, 128, 3) 0 tf_op_layer_strided_slice[0][0] _____________________________________________________________________________________ resnet50 (Model) (4, 4, 2048) 23587712 tf_op_layer_BiasAdd[0][0] _____________________________________________________________________________________ global_average_pooling2d (2048) 0 resnet50[1][0] flatten (Flatten) (2048) 0 global_average_pooling2d[0][0] _____________________________________________________________________________________ fc1 (Dense) (1) 2049 flatten[0][0] ===================================================================================== Total params: 23,589,761 Trainable params: 23,536,641 Non-trainable params: 53,120 _____________________________________________________________________________________ 5.2.4. XrayDropout Keras model \u00b6 _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= Input (InputLayer) [(128, 128, 1)] 0 _________________________________________________________________ Conv1_1 (Conv2D) (128, 128, 128) 1280 bn1 (BatchNormalization) (128, 128, 128) 512 pool1 (MaxPooling2D) (32, 32, 128) 0 _________________________________________________________________ Conv2_1 (Conv2D) (32, 32, 256) 295168 bn2 (BatchNormalization) (32, 32, 256) 1024 pool2 (MaxPooling2D) (8, 8, 256) 0 _________________________________________________________________ flatten (Flatten) (16384) 0 fc1 (Dense) (128) 2097280 bn3 (BatchNormalization) (128) 512 dropout (Dropout) (128) 0 _________________________________________________________________ fc2 (Dense) (64) 8256 bn4 (BatchNormalization) (64) 256 dropout_1 (Dropout) (64) 0 _________________________________________________________________ fc3 (Dense) (1) 65 ================================================================= Total params: 2,404,353 Trainable params: 2,403,201 Non-trainable params: 1,152 _________________________________________________________________ 5.2.5. XrayDropout2 Keras model \u00b6 _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= Input (InputLayer) (128, 128, 1) 0 _________________________________________________________________ Conv1_1 (Conv2D) (128, 128, 64) 640 bn1 (BatchNormalization) (128, 128, 64) 256 pool1 (MaxPooling2D) (64, 64, 64) 0 _________________________________________________________________ Conv2_1 (Conv2D) (64, 64, 128) 73856 bn2 (BatchNormalization) (64, 64, 128) 512 pool2 (MaxPooling2D) (32, 32, 128) 0 _________________________________________________________________ Conv3_1 (Conv2D) (32, 32, 256) 295168 bn3 (BatchNormalization) (32, 32, 256) 1024 pool3 (MaxPooling2D) (16, 16, 256) 0 _________________________________________________________________ Conv4_1 (Conv2D) (16, 16, 512) 1180160 bn4 (BatchNormalization) (16, 16, 512) 2048 pool4 (MaxPooling2D) (8, 8, 512) 0 _________________________________________________________________ Conv5_1 (Conv2D) (8, 8, 512) 2359808 bn5 (BatchNormalization) (8, 8, 512) 2048 pool5 (MaxPooling2D) (4, 4, 512) 0 _________________________________________________________________ flatten (Flatten) (8192) 0 fc1 (Dense) (256) 2097408 bn6 (BatchNormalization) (256) 1024 dropout (Dropout) (256) 0 _________________________________________________________________ fc2 (Dense) (128) 32896 bn7 (BatchNormalization) (128) 512 dropout_1 (Dropout) (128) 0 _________________________________________________________________ fc3 (Dense) (64) 8256 bn8 (BatchNormalization) (64) 256 dropout_2 (Dropout) (64) 0 _________________________________________________________________ fc4 (Dense) (1) 65 ================================================================= Total params: 6,055,937 Trainable params: 6,052,097 Non-trainable params: 3,840 _________________________________________________________________ 5.2.6. XrayVGG16 Keras model \u00b6 _____________________________________________________________________________________ Layer (type) Output Shape Param # Connected to ===================================================================================== Input (InputLayer) (128, 128, 1) 0 _____________________________________________________________________________________ concatenate (Concatenate) (128, 128, 3) 0 Input[0][0] Input[0][0] Input[0][0] _____________________________________________________________________________________ tf_op_layer_mul (128, 128, 3) 0 concatenate[0][0] Tf_op_layer_strided_slice (28, 128, 3) 0 tf_op_layer_mul[0][0] tf_op_layer_BiasAdd (128, 128, 3) 0 tf_op_layer_strided_slice[0][0] _____________________________________________________________________________________ vgg16 (Model) (4, 4, 512) 14714688 tf_op_layer_BiasAdd[0][0] _____________________________________________________________________________________ flatten (Flatten) (8192) 0 vgg16[1][0] fc1 (Dense) (1) 8193 flatten[0][0] ===================================================================================== Total params: 14,722,881 Trainable params: 14,722,881 Non-trainable params: 0 _____________________________________________________________________________________ 5.2.7. XrayMini Keras model \u00b6 _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= Input (InputLayer) [(128, 128, 1)] 0 _________________________________________________________________ Conv1_1 (Conv2D) (128, 128, 128) 1280 bn1 (BatchNormalization) (128, 128, 128) 512 pool1 (MaxPooling2D) (32, 32, 128) 0 _________________________________________________________________ Conv2_1 (Conv2D) (32, 32, 256) 295168 bn2 (BatchNormalization) (32, 32, 256) 1024 pool2 (MaxPooling2D) (8, 8, 256) 0 _________________________________________________________________ flatten (Flatten) (16384) 0 fc1 (Dense) (1) 16385 ================================================================= Total params: 314,369 Trainable params: 313,601 Non-trainable params: 768 _________________________________________________________________ 5.2.7. XrayOneMB Keras model \u00b6 _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= Input (InputLayer) (128, 128, 1) 0 _________________________________________________________________ Conv1_1 (Conv2D) (128, 128, 64) 640 bn1_1 (BatchNormalization) (128, 128, 64) 256 Conv1_2 (Conv2D) (128, 128, 64) 36928 bn1_2 (BatchNormalization) (128, 128, 64) 256 pool1 (MaxPooling2D) (64, 64, 64) 0 _________________________________________________________________ Conv2_1 (Conv2D) (64, 64, 64) 36928 bn2_1 (BatchNormalization) (64, 64, 64) 256 Conv2_2 (Conv2D) (64, 64, 64) 36928 bn2_2 (BatchNormalization) (64, 64, 64) 256 pool2 (MaxPooling2D) (32, 32, 64) 0 _________________________________________________________________ Conv3_1 (Conv2D) (32, 32, 128) 73856 bn3_1 (BatchNormalization) (32, 32, 128) 512 Conv3_2 (SeparableConv2D) (32, 32, 128) 17664 bn3_2 (BatchNormalization) (32, 32, 128) 512 pool3 (MaxPooling2D) (16, 16, 128) 0 _________________________________________________________________ Conv4_1 (SeparableConv2D) (16, 16, 128) 17664 bn4_1 (BatchNormalization) (16, 16, 128) 512 _________________________________________________________________ Conv4_2 (SeparableConv2D) (16, 16, 128) 17664 bn4_2 (BatchNormalization) (16, 16, 128) 512 _________________________________________________________________ pool4 (AveragePooling2D) (4, 4, 128) 0 flatten (Flatten) (2048) 0 _________________________________________________________________ fc1 (Dense) (1) 2049 ================================================================= Total params: 243,393 Trainable params: 241,857 Non-trainable params: 1,536 _________________________________________________________________","title":"1. CIFAR10 dataset"},{"location":"tasks/#1-cifar10-dataset","text":"","title":"1. CIFAR10 dataset"},{"location":"tasks/#11-information-and-installation","text":"","title":"1.1. Information and installation"},{"location":"tasks/#111-information-about-the-dataset","text":"The CIFAR-10 dataset consists of 60000 32x32x3 colour images in 10 classes, with 6000 images per class. The 10 different classes represent airplanes, cars, birds, cats, deer, dogs, frogs, horses, ships, and trucks Input for NN are raw 32x32 3 channels GRB images NN output is distribution of probabilities for each class i.e. 10 values that sums up to 1 Code folder: here Invoke parameter: -t CIFAR10","title":"1.1.1. Information about the dataset"},{"location":"tasks/#112-requirements","text":"Cifar dataset is loaded from tensorflow.keras.datasets.cifar10 and no stored data are required","title":"1.1.2. Requirements"},{"location":"tasks/#12-models","text":"","title":"1.2. Models"},{"location":"tasks/#121-cifar10conv-keras-model","text":"_________________________________________________________________ Layer (type) Output Shape Param # ================================================================= Input (InputLayer) (32, 32, 3) 0 _________________________________________________________________ Conv1_1 (Conv2D) (32, 32, 64) 1792 bn1_1 (BatchNormalization) (32, 32, 64) 256 Conv1_2 (Conv2D) (32, 32, 64) 36928 bn1_2 (BatchNormalization) (32, 32, 64) 256 pool1 (MaxPooling2D) (16, 16, 64) 0 _________________________________________________________________ Conv2_1 (Conv2D) (16, 16, 128 73856 bn2_1 (BatchNormalization) (16, 16, 128 512 Conv2_2 (Conv2D) (16, 16, 128 147584 bn2_2 (BatchNormalization) (16, 16, 128 512 pool2 (MaxPooling2D) (8, 8, 128) 0 _________________________________________________________________ Conv3_1 (Conv2D) (8, 8, 256) 295168 bn3_1 (BatchNormalization) (8, 8, 256) 1024 Conv3_2 (Conv2D) (8, 8, 256) 590080 bn3_2 (BatchNormalization) (8, 8, 256) 1024 Conv3_3 (Conv2D) (8, 8, 256) 590080 bn3_3 (BatchNormalization) (8, 8, 256) 1024 _________________________________________________________________ flatten (Flatten) (16384) 0 fc1 (Dense) (100) 1638500 fc2 (Dense) (10) 1010 ================================================================= Total params: 3,379,606 Trainable params: 3,377,302 Non-trainable params: 2,304 _________________________________________________________________","title":"1.2.1. CIFAR10Conv Keras model"},{"location":"tasks/#122-cifar10conv2-keras-model","text":"_________________________________________________________ Layer (type) Output Shape Param # ========================================================= Input (InputLayer) (32, 32, 3) 0 _________________________________________________________ Conv1_1 (Conv2D) (32, 32, 32) 896 Conv1_2 (Conv2D) (32, 32, 32) 9248 pool1 (MaxPooling2D) (16, 16, 32) 0 _________________________________________________________ Conv2_1 (Conv2D) (16, 16, 64) 18496 Conv2_2 (Conv2D) (16, 16, 64) 36928 pool2 (MaxPooling2D) (8, 8, 64) 0 _________________________________________________________ Conv3_1 (Conv2D) (8, 8, 128) 73856 Conv3_2 (Conv2D) (8, 8, 128) 147584 pool3 (MaxPooling2D) (4, 4, 128) 0 _________________________________________________________ flatten (Flatten) (2048) 0 fc1 (Dense) (128) 262272 fc2 (Dense) (10) 1290 ========================================================= Total params: 550,570 Trainable params: 550,570 Non-trainable params: 0 _________________________________________________________","title":"1.2.2. CIFAR10Conv2 Keras model"},{"location":"tasks/#123-cifar10resnet50-keras-model","text":"________________________________________________________ Layer (type) Output Shape Param # ======================================================== Input (InputLayer) (32, 32, 3)] 0 ________________________________________________________ resnet50 (Model) (1, 1, 2048) 23587712 ________________________________________________________ Global_average_pooling2d (2048) 0 flatten (Flatten) (2048) 0 fc1 (Dense) (10) 20490 ======================================================== Total params: 23,608,202 Trainable params: 23,555,082 Non-trainable params: 53,120 ________________________________________________________","title":"1.2.3. CIFAR10Resnet50 Keras model"},{"location":"tasks/#2-covid-x-ray-dataset","text":"","title":"2. Covid X-RAY dataset"},{"location":"tasks/#21-information-and-installation","text":"","title":"2.1. Information and installation"},{"location":"tasks/#211-information-about-the-dataset","text":"The Covid X-Ray dataset consists of grayscale images, there are 478 covid images and 203 normal images. To increase the number of images normal/pneumonia dataset is added Final dataset, which is a combination of two previously mentioned datasets, contains 1434 images, 478 images for each class. Images are cropped and resized to 512x512 pixel and spatial domain (Texture, GLDM, GLCM) and frequency domain (FFT and Wavelet) features are used to create 256 dimensional vector representation of each image. PCA is applied after to reduce dimensionality to 64 values which represents the first 64 highest eigenvalues of the covariance matrix. Input for NN are 64 values for each image NN output is distribution of probabilities for each class i.e. 3 values Code folder: here Invoke parameter: -t COVID","title":"2.1.1. Information about the dataset"},{"location":"tasks/#212-requirements","text":"Download Covid dataset: here Download pneumonia dataset: here","title":"2.1.2 Requirements"},{"location":"tasks/#22-models","text":"","title":"2.2. Models"},{"location":"tasks/#221-covid-xray-keras-model","text":"_________________________________________________________ Layer (type) Output Shape Param # ========================================================= input_1 (InputLayer) (64) 0 _________________________________________________________ dense (Dense) (128) 8320 dropout (Dropout) (128) 0 _________________________________________________________ dense_1 (Dense) (16) 2064 dropout_1 (Dropout) (16) 0 _________________________________________________________ dense_2 (Dense) (3) 51 ========================================================= Total params: 10,435 Trainable params: 10,435 Non-trainable params: 0 _________________________________________________________","title":"2.2.1. Covid XRAY Keras model"},{"location":"tasks/#3-fraud-dataset","text":"","title":"3. FRAUD dataset"},{"location":"tasks/#31-information-and-installation","text":"","title":"3.1. Information and installation"},{"location":"tasks/#311-information-about-the-dataset","text":"EEE-CIS Fraud Detection, contains multiple files with credit card transactions Raw dataset files are automatically merged and pre-processed and input files for neural network are created X.csv with data - has 431 values for each transaction Y.csv with labels - v has 1 value for each transaction 0 = not a fraud 1 = fraud Code folder: here Invoke parameter: -t FRAUD","title":"3.1.1. Information about the dataset"},{"location":"tasks/#312-requirements","text":"Download dataset: here","title":"3.1.2. Requirements"},{"location":"tasks/#32-models","text":"","title":"3.2. Models"},{"location":"tasks/#321-frauddense1-keras-model","text":"_________________________________________________________ Layer (type) Output Shape Param # ========================================================= Input (InputLayer) (431) 0 _________________________________________________________ dense (Dense) (512) 221184 Batch_normalization (512) 2048 _________________________________________________________ dense_1 (Dense) (512) 262656 Batch_normalization_1 (512) 2048 _________________________________________________________ dense_2 (Dense) (512) 262656 Batch_normalization_2 (512) 2048 _________________________________________________________ fc1 (Dense) (1) 513 ========================================================= Total params: 753,153 Trainable params: 750,081 Non-trainable params: 3,072 _________________________________________________________","title":"3.2.1. FraudDense1 Keras model"},{"location":"tasks/#322-fraudsvm-scikit-learn-model","text":"Model is defined as SGDClassifier(max_iter=1, verbose=0, loss=\"modified_huber\") Which is support vector machine linear classifier","title":"3.2.2. FraudSVM Scikit-learn model"},{"location":"tasks/#4-mnist","text":"","title":"4. MNIST"},{"location":"tasks/#41-information-and-installation","text":"","title":"4.1. Information and installation"},{"location":"tasks/#411-information-about-the-dataset","text":"This is a dataset of 70,000 28x28x1 grayscale images of the 10 digits Input for NN are raw 28x28 1 channel images NN output is distribution of probabilities for each class i.e. 10 values that sums up to 1 Code folder: here Invoke parameter: -t MNIST","title":"4.1.1. Information about the dataset"},{"location":"tasks/#412-requirements","text":"MNIST dataset is loaded from tensorflow.keras.datasets.cifar10 and no stored data are required","title":"4.1.2 Requirements"},{"location":"tasks/#42-models","text":"","title":"4.2. Models"},{"location":"tasks/#421-mnistconv-keras-model","text":"_________________________________________________________ Layer (type) Output Shape Param # ========================================================= Input (InputLayer) (28, 28, 1) 0 _________________________________________________________ Conv1_1 (Conv2D) (28, 28, 64) 640 bn1 (BatchNormalization) (28, 28, 64) 256 pool1 (MaxPooling2D) (14, 14, 64) 0 _________________________________________________________ Conv2_1 (Conv2D) (14, 14, 128) 73856 bn4 (BatchNormalization) (14, 14, 128) 512 pool2 (MaxPooling2D) (7, 7, 128) 0 _________________________________________________________ flatten (Flatten) (6272) 0 fc1 (Dense) (10) 62730 ========================================================= Total params: 137,994 Trainable params: 137,610 Non-trainable params: 384 _________________________________________________________","title":"4.2.1. MNISTConv Keras model"},{"location":"tasks/#422-mnist-pytorch-model","text":"--------------------------------------------------------- Layer (type) Output Shape Param # ========================================================= Input [28,28,1] 0 Conv2d-1 [20, 24, 24] 520 Conv2d-2 [50, 8, 8] 25,050 Linear-3 [500] 400,500 Linear-4 [10] 5,010 ========================================================= Total params: 431,080 Trainable params: 431,080 Non-trainable params: 0 ---------------------------------------------------------","title":"4.2.2. MNIST Pytorch model"},{"location":"tasks/#423-mnistsupermini-keras-model","text":"________________________________________________________________________________________ Layer (type) Output Shape Param # Connected to ======================================================================================== input_1 (InputLayer) (28, 28, 1) 0 ________________________________________________________________________________________ conv2d (Conv2D) (26, 26, 8) 80 input_1[0][0] Batch_normalization (26, 26, 8) 32 conv2d[0][0] Max_pooling2d (13, 13, 8) 0 batch_normalization[0][0] dropout (Dropout) (13, 13, 8) 0 max_pooling2d[0][0] ________________________________________________________________________________________ Separable_conv2d (11, 11, 26) 306 dropout[0][0] batch_normalization_1 (11, 11, 26) 104 separable_conv2d[0][0] dropout_1 (Dropout) (11, 11, 26) 0 batch_normalization_1[0][0] ________________________________________________________________________________________ Separable_conv2d_1 (11, 11, 26) 936 dropout_1[0][0] dropout_2[0][0] dropout_3[0][0] ________________________________________________________________________________________ Batch_normalization_2 (11, 11, 26) 104 separable_conv2d_1[0][0] dropout_2 (Dropout) (11, 11, 26) 0 batch_normalization_2[0][0] ________________________________________________________________________________________ Batch_normalization_3 (11, 11, 26) 104 separable_conv2d_1[1][0] dropout_3 (Dropout) (11, 11, 26) 0 batch_normalization_3[0][0] ________________________________________________________________________________________ Batch_normalization_4 (11, 11, 26) 104 separable_conv2d_1[2][0] dropout_4 (Dropout) (11, 11, 26) 0 batch_normalization_4[0][0] ________________________________________________________________________________________ Global_average_pooling2d (26) 0 dropout_4[0][0] dense (Dense) (16) 432 global_average_pooling2d[0][0] Batch_normalization_5 (16) 64 dense[0][0] dropout_5 (Dropout) (16) 0 batch_normalization_5[0][0] dense_1 (Dense) (10) 170 dropout_5[0][0] ======================================================================================== Total params: 2,436 Trainable params: 2,180 Non-trainable params: 256 ________________________________________________________________________________________","title":"4.2.3. MNISTSupermini Keras model"},{"location":"tasks/#5-pneumonia-xray","text":"","title":"5. Pneumonia XRAY"},{"location":"tasks/#51-information-and-installation","text":"","title":"5.1. Information and installation"},{"location":"tasks/#511-information-about-the-dataset","text":"The Chest X-Ray Images (Pneumonia) dataset consists of 5856 grayscale images of various sizes in 2 classes (normal/pneumonia). Labels are determined by folder name - NORMAL or PNEUMONIA Input for NN are raw resized 128x128 1 channel images NN output is distribution of probabilities for each class i.e. 2 values Code folder: here Invoke parameter: -t XRAY","title":"5.1.1. Information about the dataset"},{"location":"tasks/#512-requirements","text":"Download dataset: here","title":"5.1.2 Requirements"},{"location":"tasks/#52-models","text":"","title":"5.2. Models"},{"location":"tasks/#521-xraysupermini-keras-model","text":"_________________________________________________________________ Layer (type) Output Shape Param # ================================================================= Input (InputLayer) [(128, 128, 1)] 0 _________________________________________________________________ Conv1_1 (Conv2D) (128, 128, 32) 320 _________________________________________________________________ bn1 (BatchNormalization) (128, 128, 32) 128 _________________________________________________________________ pool1 (MaxPooling2D) (32, 32, 32) 0 _________________________________________________________________ Conv2_1 (Conv2D) (32, 32, 64) 18496 _________________________________________________________________ bn2 (BatchNormalization) (32, 32, 64) 256 _________________________________________________________________ Global_max_pooling2d (64) 0 _________________________________________________________________ fc1 (Dense) (1) 65 ================================================================= Total params: 19,265 Trainable params: 19,073 Non-trainable params: 192 _________________________________________________________________","title":"5.2.1. XraySupermini Keras model"},{"location":"tasks/#522-xrayresnet50-keras-model","text":"_________________________________________________________________ Layer (type) Output Shape Param # ================================================================= Input (InputLayer) [(128, 128, 1)] 0 _________________________________________________________________ resnet50 (Model) (4, 4, 2048) 23581440 _________________________________________________________________ global_average_pooling2d (2048) 0 _________________________________________________________________ flatten (Flatten) (2048) 0 _________________________________________________________________ fc1 (Dense) (1) 2049 ================================================================= Total params: 23,583,489 Trainable params: 23,530,369 Non-trainable params: 53,120 _________________________________________________________________","title":"5.2.2. XrayResnet50 Keras model"},{"location":"tasks/#523-xraypretrainedresnet50-keras-model","text":"_____________________________________________________________________________________ Layer (type) Output Shape Param # Connected to ===================================================================================== Input (InputLayer) (128, 128, 1) 0 _____________________________________________________________________________________ concatenate (Concatenate) (128, 128, 3) 0 Input[0][0] Input[0][0] Input[0][0] _____________________________________________________________________________________ tf_op_layer_mul (128, 128, 3) 0 concatenate[0][0] tf_op_layer_strided_slice (128, 128, 3) 0 tf_op_layer_mul[0][0] tf_op_layer_BiasAdd (128, 128, 3) 0 tf_op_layer_strided_slice[0][0] _____________________________________________________________________________________ resnet50 (Model) (4, 4, 2048) 23587712 tf_op_layer_BiasAdd[0][0] _____________________________________________________________________________________ global_average_pooling2d (2048) 0 resnet50[1][0] flatten (Flatten) (2048) 0 global_average_pooling2d[0][0] _____________________________________________________________________________________ fc1 (Dense) (1) 2049 flatten[0][0] ===================================================================================== Total params: 23,589,761 Trainable params: 23,536,641 Non-trainable params: 53,120 _____________________________________________________________________________________","title":"5.2.3. XrayPretrainedResnet50 Keras model"},{"location":"tasks/#524-xraydropout-keras-model","text":"_________________________________________________________________ Layer (type) Output Shape Param # ================================================================= Input (InputLayer) [(128, 128, 1)] 0 _________________________________________________________________ Conv1_1 (Conv2D) (128, 128, 128) 1280 bn1 (BatchNormalization) (128, 128, 128) 512 pool1 (MaxPooling2D) (32, 32, 128) 0 _________________________________________________________________ Conv2_1 (Conv2D) (32, 32, 256) 295168 bn2 (BatchNormalization) (32, 32, 256) 1024 pool2 (MaxPooling2D) (8, 8, 256) 0 _________________________________________________________________ flatten (Flatten) (16384) 0 fc1 (Dense) (128) 2097280 bn3 (BatchNormalization) (128) 512 dropout (Dropout) (128) 0 _________________________________________________________________ fc2 (Dense) (64) 8256 bn4 (BatchNormalization) (64) 256 dropout_1 (Dropout) (64) 0 _________________________________________________________________ fc3 (Dense) (1) 65 ================================================================= Total params: 2,404,353 Trainable params: 2,403,201 Non-trainable params: 1,152 _________________________________________________________________","title":"5.2.4. XrayDropout Keras model"},{"location":"tasks/#525-xraydropout2-keras-model","text":"_________________________________________________________________ Layer (type) Output Shape Param # ================================================================= Input (InputLayer) (128, 128, 1) 0 _________________________________________________________________ Conv1_1 (Conv2D) (128, 128, 64) 640 bn1 (BatchNormalization) (128, 128, 64) 256 pool1 (MaxPooling2D) (64, 64, 64) 0 _________________________________________________________________ Conv2_1 (Conv2D) (64, 64, 128) 73856 bn2 (BatchNormalization) (64, 64, 128) 512 pool2 (MaxPooling2D) (32, 32, 128) 0 _________________________________________________________________ Conv3_1 (Conv2D) (32, 32, 256) 295168 bn3 (BatchNormalization) (32, 32, 256) 1024 pool3 (MaxPooling2D) (16, 16, 256) 0 _________________________________________________________________ Conv4_1 (Conv2D) (16, 16, 512) 1180160 bn4 (BatchNormalization) (16, 16, 512) 2048 pool4 (MaxPooling2D) (8, 8, 512) 0 _________________________________________________________________ Conv5_1 (Conv2D) (8, 8, 512) 2359808 bn5 (BatchNormalization) (8, 8, 512) 2048 pool5 (MaxPooling2D) (4, 4, 512) 0 _________________________________________________________________ flatten (Flatten) (8192) 0 fc1 (Dense) (256) 2097408 bn6 (BatchNormalization) (256) 1024 dropout (Dropout) (256) 0 _________________________________________________________________ fc2 (Dense) (128) 32896 bn7 (BatchNormalization) (128) 512 dropout_1 (Dropout) (128) 0 _________________________________________________________________ fc3 (Dense) (64) 8256 bn8 (BatchNormalization) (64) 256 dropout_2 (Dropout) (64) 0 _________________________________________________________________ fc4 (Dense) (1) 65 ================================================================= Total params: 6,055,937 Trainable params: 6,052,097 Non-trainable params: 3,840 _________________________________________________________________","title":"5.2.5. XrayDropout2 Keras model"},{"location":"tasks/#526-xrayvgg16-keras-model","text":"_____________________________________________________________________________________ Layer (type) Output Shape Param # Connected to ===================================================================================== Input (InputLayer) (128, 128, 1) 0 _____________________________________________________________________________________ concatenate (Concatenate) (128, 128, 3) 0 Input[0][0] Input[0][0] Input[0][0] _____________________________________________________________________________________ tf_op_layer_mul (128, 128, 3) 0 concatenate[0][0] Tf_op_layer_strided_slice (28, 128, 3) 0 tf_op_layer_mul[0][0] tf_op_layer_BiasAdd (128, 128, 3) 0 tf_op_layer_strided_slice[0][0] _____________________________________________________________________________________ vgg16 (Model) (4, 4, 512) 14714688 tf_op_layer_BiasAdd[0][0] _____________________________________________________________________________________ flatten (Flatten) (8192) 0 vgg16[1][0] fc1 (Dense) (1) 8193 flatten[0][0] ===================================================================================== Total params: 14,722,881 Trainable params: 14,722,881 Non-trainable params: 0 _____________________________________________________________________________________","title":"5.2.6. XrayVGG16 Keras model"},{"location":"tasks/#527-xraymini-keras-model","text":"_________________________________________________________________ Layer (type) Output Shape Param # ================================================================= Input (InputLayer) [(128, 128, 1)] 0 _________________________________________________________________ Conv1_1 (Conv2D) (128, 128, 128) 1280 bn1 (BatchNormalization) (128, 128, 128) 512 pool1 (MaxPooling2D) (32, 32, 128) 0 _________________________________________________________________ Conv2_1 (Conv2D) (32, 32, 256) 295168 bn2 (BatchNormalization) (32, 32, 256) 1024 pool2 (MaxPooling2D) (8, 8, 256) 0 _________________________________________________________________ flatten (Flatten) (16384) 0 fc1 (Dense) (1) 16385 ================================================================= Total params: 314,369 Trainable params: 313,601 Non-trainable params: 768 _________________________________________________________________","title":"5.2.7. XrayMini Keras model"},{"location":"tasks/#527-xrayonemb-keras-model","text":"_________________________________________________________________ Layer (type) Output Shape Param # ================================================================= Input (InputLayer) (128, 128, 1) 0 _________________________________________________________________ Conv1_1 (Conv2D) (128, 128, 64) 640 bn1_1 (BatchNormalization) (128, 128, 64) 256 Conv1_2 (Conv2D) (128, 128, 64) 36928 bn1_2 (BatchNormalization) (128, 128, 64) 256 pool1 (MaxPooling2D) (64, 64, 64) 0 _________________________________________________________________ Conv2_1 (Conv2D) (64, 64, 64) 36928 bn2_1 (BatchNormalization) (64, 64, 64) 256 Conv2_2 (Conv2D) (64, 64, 64) 36928 bn2_2 (BatchNormalization) (64, 64, 64) 256 pool2 (MaxPooling2D) (32, 32, 64) 0 _________________________________________________________________ Conv3_1 (Conv2D) (32, 32, 128) 73856 bn3_1 (BatchNormalization) (32, 32, 128) 512 Conv3_2 (SeparableConv2D) (32, 32, 128) 17664 bn3_2 (BatchNormalization) (32, 32, 128) 512 pool3 (MaxPooling2D) (16, 16, 128) 0 _________________________________________________________________ Conv4_1 (SeparableConv2D) (16, 16, 128) 17664 bn4_1 (BatchNormalization) (16, 16, 128) 512 _________________________________________________________________ Conv4_2 (SeparableConv2D) (16, 16, 128) 17664 bn4_2 (BatchNormalization) (16, 16, 128) 512 _________________________________________________________________ pool4 (AveragePooling2D) (4, 4, 128) 0 flatten (Flatten) (2048) 0 _________________________________________________________________ fc1 (Dense) (1) 2049 ================================================================= Total params: 243,393 Trainable params: 241,857 Non-trainable params: 1,536 _________________________________________________________________","title":"5.2.7. XrayOneMB Keras model"}]}